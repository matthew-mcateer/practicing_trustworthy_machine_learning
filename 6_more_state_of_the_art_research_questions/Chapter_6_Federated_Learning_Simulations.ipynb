{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_fxb3DbmIFx"
      },
      "source": [
        "# Chapter 6: Federated Learning Simulations\n",
        "\n",
        "| Chapter  | Colab   | Kaggle          | Gradient      | Studio Lab             | Binder             |\n",
        "|:---------|:--------|:----------------|:--------------|:-----------------------|:-------------------|\n",
        "| [Chapter 6: Federated Learning Simulations](6_more_state_of_the_art_research_questions/Chapter_6_Federated_Learning_Simulations.ipynb)               | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/6_more_state_of_the_art_research_questions/Chapter_6_Federated_Learning_Simulations.ipynb)          | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/6_more_state_of_the_art_research_questions/Chapter_6_Federated_Learning_Simulations.ipynb)          | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/6_more_state_of_the_art_research_questions/Chapter_6_Federated_Learning_Simulations.ipynb)          | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/6_more_state_of_the_art_research_questions/Chapter_6_Federated_Learning_Simulations.ipynb)          | [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/matthew-mcateer/practicing_trustworthy_machine_learning/HEAD?urlpath=https%3A%2F%2Fgithub.com%2Fmatthew-mcateer%2Fpracticing_trustworthy_machine_learning%2Fblob%2Fmain%2F6_more_state_of_the_art_research_questions%2FChapter_6_Federated_Learning_Simulations.ipynb)         |\n",
        "\n",
        "\n",
        "<!--\n",
        "Originally found on GitHub at https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/6_more_state_of_the_art_research_questions/Chapter_6_Federated_Learning_Simulations.ipynb\n",
        "-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aksc7_Ainj6y"
      },
      "source": [
        "## FLUTE: Federated Learning Utilities and Tools for Experimentation\n",
        "\n",
        "Federated learning (FL) provides privacy and accountability benefits to machine learning pipelines.\n",
        "However, like any distributed system, there come additional engineering challenges.\n",
        "One thing that can make federated learning easier is being able to simulate your FL approach ahead of time.\n",
        "\n",
        "One such tool for this is Microsoft's FLUTE tool, which lets you use a multi-GPU environment to simulate federated learning algorithms that have been spread out among many different devices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vphR0OG2x3sV",
        "outputId": "3bf1ed2c-5016-4f1d-f7c1-f591e5c3fc7b"
      },
      "outputs": [],
      "source": [
        "# Recommend checking that you have multiple indexable GPUs for these simulations\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS3zncNuocLa"
      },
      "source": [
        "## Installation\n",
        "\n",
        "The FLUTE requirements are listed in the `requirements.txt`. Ideally this installation should be done inside of a virtual environment or docker container\n",
        "\n",
        "FLUTE uses [`torch.distributed API`](https://pytorch.org/docs/stable/distributed.html) as its main communication backbone, supporting three built-in backends.\n",
        "The authors recommend using the NCCL backend for distributed GPU training and Gloo for distributed CPU training.\n",
        "\n",
        "FLUTE is not available as a package from sources like `conda` or `pip`. This is partly because the authors intend for experiments and prototypes to be run from the root of the FLUTE repo directly.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw7gL_zWmIF2",
        "outputId": "f1ed94d2-cf35-4a0b-d20a-2dccc20e3477"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/microsoft/msrflute.git\n",
        "%cd msrflute\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1qtWIpfpD_b"
      },
      "source": [
        "Once the initial setup is complete, you can add your own dataset to the local repo to launch a local run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FclRSmVmxauO"
      },
      "source": [
        "### Example datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqkroPSQpZuy",
        "outputId": "b11caa34-5655-4a9a-b035-1fc3ac939728"
      },
      "outputs": [],
      "source": [
        "%cd testing\n",
        "!python create_data.py --task nlg_gru\n",
        "!python create_data.py --task mlm_bert\n",
        "!python create_data.py --task classif_cnn\n",
        "!python create_data.py --task ecg_cnn\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwxmsqhRpNNJ"
      },
      "source": [
        "### Example task #1: `nlg_gru`\n",
        "\n",
        "After this initial setup you can use your data for launching a local run. However the following instructions will be adapted to run `nlg_gru` task.\n",
        "\n",
        "This task involves training a GRU model on the preprocessed reddit dataset by [LEAF: A Benchmark for Federated Settings](https://arxiv.org/abs/1812.01097)\n",
        "\n",
        "For running this example, you need to first download and preprocess the data. Instructions can be found [here](https://github.com/microsoft/msrflute/tree/main/testing).\n",
        "\n",
        "Once the data is available you can run FLUTE from root as follows (using the GPU-only `NCCL` backend)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rh805xnnJDr",
        "outputId": "535dfb29-f644-42ab-e935-deca0b4d4fc0"
      },
      "outputs": [],
      "source": [
        "!python -m torch.distributed.run \\\n",
        "    --nproc_per_node=4 e2e_trainer.py \\\n",
        "        -dataPath ./testing \\\n",
        "        -outputPath scratch \\\n",
        "        -config testing/hello_world_nlg_gru.yaml \\\n",
        "        -task nlg_gru \\\n",
        "        -backend nccl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5aB5Jeeqa6W"
      },
      "source": [
        "### Example task #2: `mlm_bert`\n",
        "\n",
        "This experiment trains a BERT model using Federated learning.\n",
        "\n",
        "Like the previous example, it uses the preprocessed reddit dataset by [LEAF: A Benchmark for Federated Settings](https://arxiv.org/abs/1812.01097)\n",
        "\n",
        "For running this example, you need to first download and preprocess the data. Instructions can be found [here](https://github.com/microsoft/msrflute/tree/main/testing).\n",
        "\n",
        "Once the data is available you can run FLUTE from root as follows (using the GPU-only `NCCL` backend):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2AUQnwRrQy3"
      },
      "outputs": [],
      "source": [
        "!python -m torch.distributed.run \\\n",
        "    --nproc_per_node=4 e2e_trainer.py \\\n",
        "        -dataPath ./testing \\\n",
        "        -outputPath scratch \\\n",
        "        -config testing/hello_world_mlm_bert.yaml \\\n",
        "        -task mlm_bert \\\n",
        "        -backend nccl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk4ry4Z_qfSd"
      },
      "source": [
        "### Example task #3: `classif_cnn`\n",
        "\n",
        "For running this example, you need to first download and preprocess the data. Instructions can be found [here](https://github.com/microsoft/msrflute/tree/main/testing).\n",
        "\n",
        "This particular example trains on a divided-up version of the classic [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset for image classification.\n",
        "\n",
        "Once the data is available you can run FLUTE from root as follows (using the CPU-only `Gloo` backend):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCEA5Ls0rQcF",
        "outputId": "92d4f909-a834-49c0-e1e3-75d8c1e2f555"
      },
      "outputs": [],
      "source": [
        "!python -m torch.distributed.run \\\n",
        "    --nproc_per_node=4 e2e_trainer.py \\\n",
        "        -dataPath ./testing \\\n",
        "        -outputPath scratch \\\n",
        "        -config testing/hello_world_classif_cnn.yaml \\\n",
        "        -task classif_cnn \\\n",
        "        -backend nccl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qfXW4vBqhQR"
      },
      "source": [
        "### Example task #4: `ecg_cnn`\n",
        "\n",
        "For running this example, you need to first download and preprocess the data. Instructions can be found [here](https://github.com/microsoft/msrflute/tree/main/testing).\n",
        "\n",
        "Once the data is available you can run FLUTE from root as follows (using the CPU-only `Gloo` backend):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGtSq1esrQG1",
        "outputId": "3c43a932-c21c-49d1-ed73-f0998ae2bcad"
      },
      "outputs": [],
      "source": [
        "!python -m torch.distributed.run \\\n",
        "    --nproc_per_node=4 e2e_trainer.py \\\n",
        "        -dataPath ./testing \\\n",
        "        -outputPath scratch \\\n",
        "        -config testing/hello_world_ecg_cnn.yaml \\\n",
        "        -task ecg_cnn \\\n",
        "        -backend gloo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO5LxkjqmOQU"
      },
      "source": [
        "# References\n",
        "\n",
        "- [FLUTE Overview — FLUTE  documentation](https://microsoft.github.io/msrflute/overview.html)\n",
        "- [Welcome to FLUTE documentation! — FLUTE  documentation](https://microsoft.github.io/msrflute/)\n",
        "- [microsoft/msrflute: Federated Learning Utilities and Tools for Experimentation](https://github.com/microsoft/msrflute)\n",
        "- [Project FLUTE - Microsoft Research](https://www.microsoft.com/en-us/research/project/project-flute/)\n",
        "- [Caldas, S., Duddu, S. M. K., Wu, P., Li, T., Konečný, J., McMahan, H. B., ... & Talwalkar, A. (2018). Leaf: A benchmark for federated settings. arXiv preprint arXiv:1812.01097.](https://arxiv.org/abs/1812.01097)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit ('3.9.0')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0 (default, Dec 11 2020, 03:26:52) \n[Clang 12.0.0 (clang-1200.0.32.21)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b6b7e97e50c754c7aee36d85160e6764033ec8a20165f676e018446c78d531c2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
