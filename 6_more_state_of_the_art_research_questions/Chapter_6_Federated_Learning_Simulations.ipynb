{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_fxb3DbmIFx"
      },
      "source": [
        "# Chapter 6: Federated Learning Simulations\n",
        "\n",
        "\n",
        "| **Platform**           | **Link**                                                                                                                                                                                                                                                                                               | **Notes**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
        "|------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| _Local Folder_         | [Deep Dive Example: Federated Learning Simulations](6_more_state_of_the_art_research_questions/Chapter_6_Federated_Learning_Simulations.ipynb)                                                                                                                                                                                                                                |  `6_more_state_of_the_art_research_questions/`<br>`Chapter_6_Federated_Learning_Simulations.ipynb`                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
        "| _Book Chapter_         | [Chapter 6: More State-of-the-Art Research Questions](https://learning.oreilly.com/library/view/practicing-trustworthy-machine/9781098120269/ch06.html)                                                                                                                                                                                 | Ebook available from [O'Reilly](https://www.oreilly.com/library/view/practicing-trustworthy-machine/9781098120269/).<br>Physical book available from [Amazon](https://www.amazon.com/Practicing-Trustworthy-Machine-Learning-Transparent/dp/1098120272)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
        "| _GitHub_               | [![GitHub](https://img.shields.io/badge/-View%20on%20GitHub-181717?logo=github&logoColor=ffffff)](https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/6_more_state_of_the_art_research_questions/Chapter_6_Federated_Learning_Simulations.ipynb)                                                                          | Please star on GitHub so others can<br>find this repo and get help with implenting<br>their trustworthy AI pipelines<br> [![GitHub forks](https://img.shields.io/github/forks/matthew-mcateer/practicing_trustworthy_machine_learning.svg?style=social&label=Fork&maxAge=2592000)](https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/network/) <br> [![GitHub stars](https://img.shields.io/github/stars/matthew-mcateer/practicing_trustworthy_machine_learning.svg?style=social&label=Star&maxAge=2592000)](https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/stargazers/) <br> [![GitHub watchers](https://img.shields.io/github/watchers/matthew-mcateer/practicing_trustworthy_machine_learning.svg?style=social&label=Watch&maxAge=2592000)](https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/watchers/) <br>[`@matthew-mcateer`](https://github.com/matthew-mcateer) [![GitHub followers](https://img.shields.io/github/followers/matthew-mcateer?style=social&label=Follow&maxAge=2592000)](https://github.com/matthew-mcateer?tab=followers)<br>[`@pruksmhc`](https://github.com/pruksmhc) [![GitHub followers](https://img.shields.io/github/followers/pruksmhc?style=social&label=Follow&maxAge=2592000)](https://github.com/pruksmhc?tab=followers)<br>[`@shubhobm`](https://github.com/shubhobm) [![GitHub followers](https://img.shields.io/github/followers/shubhobm?style=social&label=Follow&maxAge=2592000)](https://github.com/shubhobm?tab=followers)  |\n",
        "| _Colab_                | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/6_more_state_of_the_art_research_questions/Chapter_6_Federated_Learning_Simulations.ipynb)                                                                         | Enable GPU<br> Colab Pro recommended                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
        "| _Kaggle_               | [ ![ Kaggle ]( https://kaggle.com/static/images/open-in-kaggle.svg ) ]( https://kaggle.com/kernels/welcome?src=https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/6_more_state_of_the_art_research_questions/Chapter_6_Federated_Learning_Simulations.ipynb )                                                            | Enable GPU<br> Enable Internet                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
        "| _Gradient_             | [ ![ Gradient ]( https://assets.paperspace.io/img/gradient-badge.svg ) ]( https://console.paperspace.com/github/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/6_more_state_of_the_art_research_questions/Chapter_6_Federated_Learning_Simulations.ipynb )                                                                              | Enable GPU                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
        "| _SageMaker Studio Lab_ | [![ Open In SageMaker Studio Lab ]( https://studiolab.sagemaker.aws/studiolab.svg ) ]( https://studiolab.sagemaker.aws/import/github/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/6_more_state_of_the_art_research_questions/Chapter_6_Federated_Learning_Simulations.ipynb )                                                         | Recommend `ml.g4dn.xlarge` instance at minimum<br>(alternatively, `g4dn.2xlarge` if using EC2 instance)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
        "| _Binder_               | [ ![ Binder ]( https://mybinder.org/badge_logo.svg ) ]( https://mybinder.org/v2/gh/matthew-mcateer/practicing_trustworthy_machine_learning/HEAD?urlpath=https%3A%2F%2Fgithub.com%2Fmatthew-mcateer%2Fpracticing_trustworthy_machine_learning%2Fblob%2Fmain%2F6_more_state_of_the_art_research_questions%2FChapter_6_Federated_Learning_Simulations.ipynb ) | May run slowly without GPU                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
        "\n",
        "\n",
        "<!--\n",
        "Originally found on GitHub at https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/6_more_state_of_the_art_research_questions/Chapter_6_Federated_Learning_Simulations.ipynb\n",
        "-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aksc7_Ainj6y"
      },
      "source": [
        "## FLUTE: Federated Learning Utilities and Tools for Experimentation\n",
        "\n",
        "Federated learning (FL) provides privacy and accountability benefits to machine learning pipelines.\n",
        "However, like any distributed system, there come additional engineering challenges.\n",
        "One thing that can make federated learning easier is being able to simulate your FL approach ahead of time.\n",
        "\n",
        "One such tool for this is Microsoft's FLUTE tool, which lets you use a multi-GPU environment to simulate federated learning algorithms that have been spread out among many different devices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XVOTQsaEwwQ_"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "def check_if_colab() -> bool:\n",
        "    \"\"\"Check if this is being run in Google Colab.\"\"\"\n",
        "    return \"google.colab\" in sys.modules\n",
        "\n",
        "def check_if_kaggle() -> bool:\n",
        "    \"\"\"Check if this is being run in Kaggle.\"\"\"\n",
        "    return \"kaggle_secrets\" in sys.modules\n",
        "\n",
        "IS_COLAB = check_if_colab()\n",
        "IS_KAGGLE = check_if_kaggle()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXrR_WNbwu1C"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vphR0OG2x3sV",
        "outputId": "4975b64e-5c6d-4069-e701-889a76948a4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed May 31 17:07:04 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Recommend checking that you have multiple indexable GPUs for these simulations\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q1GZyePwv7N",
        "outputId": "72d89e28-15de-466e-841a-440faec82047"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Count:  1\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "# Define the first command\n",
        "command1 = ['nvidia-smi', '--list-gpus']\n",
        "\n",
        "# Run the first command\n",
        "proc1 = subprocess.Popen(command1, stdout=subprocess.PIPE)\n",
        "\n",
        "# Define the second command\n",
        "command2 = ['wc', '-l']\n",
        "\n",
        "# Run the second command with the output of the first command as input\n",
        "proc2 = subprocess.Popen(command2, stdin=proc1.stdout, stdout=subprocess.PIPE)\n",
        "\n",
        "# Allow proc1 to receive a SIGPIPE if proc2 exits\n",
        "proc1.stdout.close()\n",
        "\n",
        "# Get the output from the second command\n",
        "out, err = proc2.communicate()\n",
        "\n",
        "# Decode the output from bytes to string\n",
        "GPU_COUNT = int(out.decode('utf-8').strip())\n",
        "print(\"GPU Count: \", GPU_COUNT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoAEUBgKw1BI",
        "outputId": "1e1c63d4-73ec-414a-f1e8-ba67eb325111"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n",
            "Collecting torch==1.11.0\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torch-1.11.0%2Bcu113-cp310-cp310-linux_x86_64.whl (1637.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 GB\u001b[0m \u001b[31m830.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.12.0\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.12.0%2Bcu113-cp310-cp310-linux_x86_64.whl (22.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==0.11.0\n",
            "  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.11.0%2Bcu113-cp310-cp310-linux_x86_64.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtext==0.12.0\n",
            "  Downloading torchtext-0.12.0-cp310-cp310-manylinux1_x86_64.whl (10.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchdata==0.3.0\n",
            "  Downloading torchdata-0.3.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0) (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (8.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.12.0) (4.65.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.3.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (3.4)\n",
            "Installing collected packages: torch, torchvision, torchtext, torchdata, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.2+cu118\n",
            "    Uninstalling torchvision-0.15.2+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.2+cu118\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.15.2\n",
            "    Uninstalling torchtext-0.15.2:\n",
            "      Successfully uninstalled torchtext-0.15.2\n",
            "  Attempting uninstall: torchdata\n",
            "    Found existing installation: torchdata 0.6.1\n",
            "    Uninstalling torchdata-0.6.1:\n",
            "      Successfully uninstalled torchdata-0.6.1\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.0.2+cu118\n",
            "    Uninstalling torchaudio-2.0.2+cu118:\n",
            "      Successfully uninstalled torchaudio-2.0.2+cu118\n",
            "Successfully installed torch-1.11.0+cu113 torchaudio-0.11.0+cu113 torchdata-0.3.0 torchtext-0.12.0 torchvision-0.12.0+cu113\n"
          ]
        }
      ],
      "source": [
        "if IS_COLAB==True or IS_KAGGLE==True:\n",
        "    !pip3 install torch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0 torchtext==0.12.0 torchdata==0.3.0 --extra-index-url https://download.pytorch.org/whl/cu113"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS3zncNuocLa"
      },
      "source": [
        "\n",
        "\n",
        "The FLUTE requirements are listed in the `requirements.txt`. Ideally this installation should be done inside of a virtual environment or docker container\n",
        "\n",
        "FLUTE uses [`torch.distributed API`](https://pytorch.org/docs/stable/distributed.html) as its main communication backbone, supporting three built-in backends.\n",
        "The authors recommend using the NCCL backend for distributed GPU training and Gloo for distributed CPU training.\n",
        "\n",
        "FLUTE is not available as a package from sources like `conda` or `pip`. This is partly because the authors intend for experiments and prototypes to be run from the root of the FLUTE repo directly.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw7gL_zWmIF2",
        "outputId": "bac02eab-8255-4c3c-fadd-9a67f5d4ddb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'msrflute'...\n",
            "remote: Enumerating objects: 788, done.\u001b[K\n",
            "remote: Counting objects: 100% (788/788), done.\u001b[K\n",
            "remote: Compressing objects: 100% (392/392), done.\u001b[K\n",
            "remote: Total 788 (delta 410), reused 729 (delta 365), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (788/788), 4.74 MiB | 20.20 MiB/s, done.\n",
            "Resolving deltas: 100% (410/410), done.\n",
            "/content/msrflute\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.11.0+cu113)\n",
            "Collecting mpi4py (from -r requirements.txt (line 2))\n",
            "  Downloading mpi4py-3.1.4.tar.gz (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.10)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.10.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (5.9.5)\n",
            "Collecting transformers (from -r requirements.txt (line 6))\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m122.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.12.0+cu113)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.5.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (3.8.0)\n",
            "Collecting sphinx_rtd_theme (from -r requirements.txt (line 10))\n",
            "  Downloading sphinx_rtd_theme-1.2.1-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azureml-core (from -r requirements.txt (line 11))\n",
            "  Downloading azureml_core-1.51.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m112.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azureml-defaults (from -r requirements.txt (line 12))\n",
            "  Downloading azureml_defaults-1.51.0-py3-none-any.whl (2.0 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (6.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (1.2.2)\n",
            "Collecting cerberus (from -r requirements.txt (line 15))\n",
            "  Downloading Cerberus-1.3.4.tar.gz (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (3.20.3)\n",
            "Collecting sentencepiece (from -r requirements.txt (line 17))\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (0.4)\n",
            "Collecting wget (from -r requirements.txt (line 19))\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0->-r requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->-r requirements.txt (line 4)) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 6)) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers->-r requirements.txt (line 6))\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 6)) (23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 6)) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 6)) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers->-r requirements.txt (line 6))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 6)) (4.65.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 7)) (8.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 8)) (2022.7.1)\n",
            "Requirement already satisfied: sphinx<7,>=1.6 in /usr/local/lib/python3.10/dist-packages (from sphinx_rtd_theme->-r requirements.txt (line 10)) (3.5.4)\n",
            "Requirement already satisfied: docutils<0.19 in /usr/local/lib/python3.10/dist-packages (from sphinx_rtd_theme->-r requirements.txt (line 10)) (0.16)\n",
            "Collecting sphinxcontrib-jquery!=3.0.0,>=2.0.0 (from sphinx_rtd_theme->-r requirements.txt (line 10))\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backports.tempfile (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting pathspec<1.0.0 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading pathspec-0.11.1-py3-none-any.whl (29 kB)\n",
            "Collecting msal<2.0.0,>=1.15.0 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading msal-1.22.0-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting msal-extensions<=1.0.0,>=0.3.0 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting knack~=0.10.0 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading knack-0.10.1-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-core<2.0.0 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading azure_core-1.26.4-py3-none-any.whl (173 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.9/173.9 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pkginfo (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading pkginfo-1.9.6-py3-none-any.whl (30 kB)\n",
            "Collecting argcomplete<3 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading argcomplete-2.1.2-py3-none-any.whl (37 kB)\n",
            "Collecting humanfriendly<11.0,>=4.7 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting paramiko<4.0.0,>=2.0.8 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading paramiko-3.2.0-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.2/224.2 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-mgmt-resource<=22.0.0,>=15.0.0 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading azure_mgmt_resource-22.0.0-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-mgmt-containerregistry<11,>=8.2.0 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading azure_mgmt_containerregistry-10.1.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-mgmt-storage<=21.0.0,>=16.0.0 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading azure_mgmt_storage-21.0.0-py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-mgmt-keyvault<11.0.0,>=0.40.0 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading azure_mgmt_keyvault-10.2.2-py3-none-any.whl (780 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.2/780.2 kB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-mgmt-authorization<4,>=0.40.0 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading azure_mgmt_authorization-3.0.0-py3-none-any.whl (965 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.9/965.9 kB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-graphrbac<1.0.0,>=0.40.0 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.4/141.4 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azure-common<2.0.0,>=1.1.12 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
            "Collecting msrest<=0.7.1,>=0.5.1 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting msrestazure<=0.6.4,>=0.4.33 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<2.0.0,>=1.23 in /usr/local/lib/python3.10/dist-packages (from azureml-core->-r requirements.txt (line 11)) (1.26.15)\n",
            "Collecting packaging>=20.0 (from transformers->-r requirements.txt (line 6))\n",
            "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<41 in /usr/local/lib/python3.10/dist-packages (from azureml-core->-r requirements.txt (line 11)) (40.0.2)\n",
            "Collecting ndg-httpsclient<=0.5.1 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
            "Collecting SecretStorage<4.0.0 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: jsonpickle<4.0.0 in /usr/local/lib/python3.10/dist-packages (from azureml-core->-r requirements.txt (line 11)) (3.0.1)\n",
            "Requirement already satisfied: contextlib2<22.0.0 in /usr/local/lib/python3.10/dist-packages (from azureml-core->-r requirements.txt (line 11)) (0.6.0.post1)\n",
            "Collecting docker<7.0.0 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading docker-6.1.2-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m977.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyJWT<3.0.0 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading PyJWT-2.7.0-py3-none-any.whl (22 kB)\n",
            "Collecting adal<=1.2.7,>=1.2.0 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyopenssl<24.0.0 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading pyOpenSSL-23.2.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0 (from azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting azureml-inference-server-http~=0.8.0 (from azureml-defaults->-r requirements.txt (line 12))\n",
            "  Downloading azureml_inference_server_http-0.8.4-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azureml-dataset-runtime[fuse]~=1.51.0 (from azureml-defaults->-r requirements.txt (line 12))\n",
            "  Downloading azureml_dataset_runtime-1.51.0-py3-none-any.whl (2.3 kB)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 14)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 14)) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from cerberus->-r requirements.txt (line 15)) (67.7.2)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0->azureml-core->-r requirements.txt (line 11)) (1.16.0)\n",
            "Collecting azure-mgmt-core<2.0.0,>=1.3.2 (from azure-mgmt-authorization<4,>=0.40.0->azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB)\n",
            "Collecting isodate<1.0.0,>=0.6.1 (from azure-mgmt-keyvault<11.0.0,>=0.40.0->azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azureml-dataprep<4.11.0a,>=4.10.0a (from azureml-dataset-runtime[fuse]~=1.51.0->azureml-defaults->-r requirements.txt (line 12))\n",
            "  Downloading azureml_dataprep-4.10.7-py3-none-any.whl (38.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow<=9.0.0,>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from azureml-dataset-runtime[fuse]~=1.51.0->azureml-defaults->-r requirements.txt (line 12)) (9.0.0)\n",
            "Collecting fusepy<4.0.0,>=3.0.1 (from azureml-dataset-runtime[fuse]~=1.51.0->azureml-defaults->-r requirements.txt (line 12))\n",
            "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: flask<2.3.0 in /usr/local/lib/python3.10/dist-packages (from azureml-inference-server-http~=0.8.0->azureml-defaults->-r requirements.txt (line 12)) (2.2.4)\n",
            "Collecting flask-cors~=3.0.1 (from azureml-inference-server-http~=0.8.0->azureml-defaults->-r requirements.txt (line 12))\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Collecting inference-schema~=1.5.0 (from azureml-inference-server-http~=0.8.0->azureml-defaults->-r requirements.txt (line 12))\n",
            "  Downloading inference_schema-1.5.1-py3-none-any.whl (21 kB)\n",
            "Collecting opencensus-ext-azure~=1.1.0 (from azureml-inference-server-http~=0.8.0->azureml-defaults->-r requirements.txt (line 12))\n",
            "  Downloading opencensus_ext_azure-1.1.9-py2.py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<1.11,>=1.9 in /usr/local/lib/python3.10/dist-packages (from azureml-inference-server-http~=0.8.0->azureml-defaults->-r requirements.txt (line 12)) (1.10.7)\n",
            "Collecting gunicorn==20.1.0 (from azureml-inference-server-http~=0.8.0->azureml-defaults->-r requirements.txt (line 12))\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m608.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<41->azureml-core->-r requirements.txt (line 11)) (1.15.1)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from docker<7.0.0->azureml-core->-r requirements.txt (line 11)) (1.5.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers->-r requirements.txt (line 6)) (2023.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from knack~=0.10.0->azureml-core->-r requirements.txt (line 11)) (2.14.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from knack~=0.10.0->azureml-core->-r requirements.txt (line 11)) (0.8.10)\n",
            "Collecting portalocker<3,>=1.0 (from msal-extensions<=1.0.0,>=0.3.0->azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from msrest<=0.7.1,>=0.5.1->azureml-core->-r requirements.txt (line 11)) (2022.12.7)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from msrest<=0.7.1,>=0.5.1->azureml-core->-r requirements.txt (line 11)) (1.3.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ndg-httpsclient<=0.5.1->azureml-core->-r requirements.txt (line 11)) (0.5.0)\n",
            "Collecting bcrypt>=3.2 (from paramiko<4.0.0,>=2.0.8->azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynacl>=1.5 (from paramiko<4.0.0,>=2.0.8->azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 6)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 6)) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r requirements.txt (line 6)) (1.7.1)\n",
            "Collecting jeepney>=0.6 (from SecretStorage<4.0.0->azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx<7,>=1.6->sphinx_rtd_theme->-r requirements.txt (line 10)) (1.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx<7,>=1.6->sphinx_rtd_theme->-r requirements.txt (line 10)) (1.0.2)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx<7,>=1.6->sphinx_rtd_theme->-r requirements.txt (line 10)) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp in /usr/local/lib/python3.10/dist-packages (from sphinx<7,>=1.6->sphinx_rtd_theme->-r requirements.txt (line 10)) (2.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.10/dist-packages (from sphinx<7,>=1.6->sphinx_rtd_theme->-r requirements.txt (line 10)) (1.1.5)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx<7,>=1.6->sphinx_rtd_theme->-r requirements.txt (line 10)) (1.0.3)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.10/dist-packages (from sphinx<7,>=1.6->sphinx_rtd_theme->-r requirements.txt (line 10)) (3.1.2)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx<7,>=1.6->sphinx_rtd_theme->-r requirements.txt (line 10)) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx<7,>=1.6->sphinx_rtd_theme->-r requirements.txt (line 10)) (2.12.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx<7,>=1.6->sphinx_rtd_theme->-r requirements.txt (line 10)) (0.7.13)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx<7,>=1.6->sphinx_rtd_theme->-r requirements.txt (line 10)) (1.4.1)\n",
            "Collecting backports.weakref (from backports.tempfile->azureml-core->-r requirements.txt (line 11))\n",
            "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
            "Collecting dotnetcore2<4.0.0,>=3.0.0 (from azureml-dataprep<4.11.0a,>=4.10.0a->azureml-dataset-runtime[fuse]~=1.51.0->azureml-defaults->-r requirements.txt (line 12))\n",
            "  Downloading dotnetcore2-3.1.23-py3-none-manylinux1_x86_64.whl (31.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.1/31.1 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azureml-dataprep-native<39.0.0,>=38.0.0 (from azureml-dataprep<4.11.0a,>=4.10.0a->azureml-dataset-runtime[fuse]~=1.51.0->azureml-defaults->-r requirements.txt (line 12))\n",
            "  Downloading azureml_dataprep_native-38.0.0-cp310-cp310-manylinux1_x86_64.whl (191 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.7/191.7 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting azureml-dataprep-rslex~=2.17.6dev0 (from azureml-dataprep<4.11.0a,>=4.10.0a->azureml-dataset-runtime[fuse]~=1.51.0->azureml-defaults->-r requirements.txt (line 12))\n",
            "  Downloading azureml_dataprep_rslex-2.17.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle<3.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from azureml-dataprep<4.11.0a,>=4.10.0a->azureml-dataset-runtime[fuse]~=1.51.0->azureml-defaults->-r requirements.txt (line 12)) (2.2.1)\n",
            "Collecting azure-identity>=1.7.0 (from azureml-dataprep<4.11.0a,>=4.10.0a->azureml-dataset-runtime[fuse]~=1.51.0->azureml-defaults->-r requirements.txt (line 12))\n",
            "  Downloading azure_identity-1.13.0-py3-none-any.whl (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.6/151.6 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from azureml-dataprep<4.11.0a,>=4.10.0a->azureml-dataset-runtime[fuse]~=1.51.0->azureml-defaults->-r requirements.txt (line 12)) (4.3.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<41->azureml-core->-r requirements.txt (line 11)) (2.21)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask<2.3.0->azureml-inference-server-http~=0.8.0->azureml-defaults->-r requirements.txt (line 12)) (2.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask<2.3.0->azureml-inference-server-http~=0.8.0->azureml-defaults->-r requirements.txt (line 12)) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask<2.3.0->azureml-inference-server-http~=0.8.0->azureml-defaults->-r requirements.txt (line 12)) (8.1.3)\n",
            "Collecting wrapt<=1.12.1,>=1.11.1 (from inference-schema~=1.5.0->azureml-inference-server-http~=0.8.0->azureml-defaults->-r requirements.txt (line 12))\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.3->sphinx<7,>=1.6->sphinx_rtd_theme->-r requirements.txt (line 10)) (2.1.2)\n",
            "Collecting opencensus<1.0.0,>=0.11.2 (from opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.8.0->azureml-defaults->-r requirements.txt (line 12))\n",
            "  Downloading opencensus-0.11.2-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.5.0->msrest<=0.7.1,>=0.5.1->azureml-core->-r requirements.txt (line 11)) (3.2.2)\n",
            "Collecting distro>=1.2.0 (from dotnetcore2<4.0.0,>=3.0.0->azureml-dataprep<4.11.0a,>=4.10.0a->azureml-dataset-runtime[fuse]~=1.51.0->azureml-defaults->-r requirements.txt (line 12))\n",
            "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus<1.0.0,>=0.11.2->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.8.0->azureml-defaults->-r requirements.txt (line 12))\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus<1.0.0,>=0.11.2->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.8.0->azureml-defaults->-r requirements.txt (line 12)) (2.11.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->azureml-dataprep<4.11.0a,>=4.10.0a->azureml-dataset-runtime[fuse]~=1.51.0->azureml-defaults->-r requirements.txt (line 12)) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->azureml-dataprep<4.11.0a,>=4.10.0a->azureml-dataset-runtime[fuse]~=1.51.0->azureml-defaults->-r requirements.txt (line 12)) (0.19.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.8.0->azureml-defaults->-r requirements.txt (line 12)) (1.59.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.8.0->azureml-defaults->-r requirements.txt (line 12)) (2.17.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.8.0->azureml-defaults->-r requirements.txt (line 12)) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.8.0->azureml-defaults->-r requirements.txt (line 12)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus<1.0.0,>=0.11.2->opencensus-ext-azure~=1.1.0->azureml-inference-server-http~=0.8.0->azureml-defaults->-r requirements.txt (line 12)) (4.9)\n",
            "Building wheels for collected packages: mpi4py, cerberus, wget, fusepy, wrapt\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.4-cp310-cp310-linux_x86_64.whl size=3365680 sha256=637218fb093f665c4273811d67849d053371c9fd190d9cb475aa2ab853f7c474\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/1b/b5/97ec4cfccdde26e0f3590ad6e09a5242d508dff09704ef86c1\n",
            "  Building wheel for cerberus (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cerberus: filename=Cerberus-1.3.4-py3-none-any.whl size=58193 sha256=449cf763c2a435fa1e5f1e55393517a482e533d91f37cb980284bead3db505ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/1f/a3/075fbe965309e96fbbd681d8f1829b10c9da8afb60ee3d137d\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=54eb448abdf51888ba379e76fc41040eedd1decae5c4b1b33b630c8745ca2007\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "  Building wheel for fusepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10486 sha256=5a620db1e4a25c44ef9b9e76e4d8967c2270b97053c6d37cc0e07ed8e264d5f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/18/f6/f0d6be9d0435e2677ce5cc758e91da50053dce456a346f08c5\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp310-cp310-linux_x86_64.whl size=76119 sha256=743359e61fff6782f073704db4f891e330677b419eaef3b6e32a7254fa12a3a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/61/d3/d9e7053100177668fa43216a8082868c55015f8706abd974f2\n",
            "Successfully built mpi4py cerberus wget fusepy wrapt\n",
            "Installing collected packages: wrapt, wget, tokenizers, sentencepiece, opencensus-context, fusepy, backports.weakref, azureml-dataprep-rslex, azureml-dataprep-native, azure-common, PyJWT, portalocker, pkginfo, pathspec, packaging, mpi4py, jmespath, jeepney, isodate, humanfriendly, gunicorn, distro, cerberus, bcrypt, backports.tempfile, argcomplete, pynacl, knack, inference-schema, huggingface-hub, dotnetcore2, docker, azure-core, transformers, sphinxcontrib-jquery, SecretStorage, pyopenssl, paramiko, msrest, flask-cors, azure-mgmt-core, adal, sphinx_rtd_theme, opencensus, ndg-httpsclient, msrestazure, msal, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, msal-extensions, azure-graphrbac, azureml-core, azure-identity, opencensus-ext-azure, azureml-dataprep, azureml-inference-server-http, azureml-dataset-runtime, azureml-defaults\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.1\n",
            "    Uninstalling packaging-23.1:\n",
            "      Successfully uninstalled packaging-23.1\n",
            "Successfully installed PyJWT-2.7.0 SecretStorage-3.3.3 adal-1.2.7 argcomplete-2.1.2 azure-common-1.1.28 azure-core-1.26.4 azure-graphrbac-0.61.1 azure-identity-1.13.0 azure-mgmt-authorization-3.0.0 azure-mgmt-containerregistry-10.1.0 azure-mgmt-core-1.4.0 azure-mgmt-keyvault-10.2.2 azure-mgmt-resource-22.0.0 azure-mgmt-storage-21.0.0 azureml-core-1.51.0 azureml-dataprep-4.10.7 azureml-dataprep-native-38.0.0 azureml-dataprep-rslex-2.17.11 azureml-dataset-runtime-1.51.0 azureml-defaults-1.51.0 azureml-inference-server-http-0.8.4 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-4.0.1 cerberus-1.3.4 distro-1.8.0 docker-6.1.2 dotnetcore2-3.1.23 flask-cors-3.0.10 fusepy-3.0.1 gunicorn-20.1.0 huggingface-hub-0.14.1 humanfriendly-10.0 inference-schema-1.5.1 isodate-0.6.1 jeepney-0.8.0 jmespath-1.0.1 knack-0.10.1 mpi4py-3.1.4 msal-1.22.0 msal-extensions-1.0.0 msrest-0.7.1 msrestazure-0.6.4 ndg-httpsclient-0.5.1 opencensus-0.11.2 opencensus-context-0.1.3 opencensus-ext-azure-1.1.9 packaging-23.0 paramiko-3.2.0 pathspec-0.11.1 pkginfo-1.9.6 portalocker-2.7.0 pynacl-1.5.0 pyopenssl-23.2.0 sentencepiece-0.1.99 sphinx_rtd_theme-1.2.1 sphinxcontrib-jquery-4.1 tokenizers-0.13.3 transformers-4.29.2 wget-3.2 wrapt-1.12.1\n"
          ]
        }
      ],
      "source": [
        "if IS_COLAB==True or IS_KAGGLE==True:\n",
        "    !git clone https://github.com/microsoft/msrflute.git\n",
        "    %cd msrflute\n",
        "    !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1qtWIpfpD_b"
      },
      "source": [
        "Once the initial setup is complete, you can add your own dataset to the local repo to launch a local run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FclRSmVmxauO"
      },
      "source": [
        "### Example datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4TzKaJ0wBT8"
      },
      "source": [
        "Now, the FLUTE library comes with a selection of example datasets to use:\n",
        "\n",
        "|Task|Data Set|Model|Algorithm|# Clients|Clients per round|Batch Size|Client Optimizer|lr|Epochs|# Rounds|Test Freq|\n",
        "|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|:----|\n",
        "|CV|MNIST|LR|FedAvg|1000|10|10|SGD|0.03|1|100|20|\n",
        "|CV|Federated EMNIST|CNN (2 Conv + 2 FC)|FedAvg|3400|10|20|SGD|0.1|1|1500|50|\n",
        "|CV|FED_CIFAR-100|ResNet-18+group normalization|FedAvg|500|10|20|SGD|0.1|1|4000|50|\n",
        "|NLP|Shakespeare|RNN (2 LSTM + 1 FC)|FedAvg|715|10|4|SGD|0.8|1|1200|50|\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqkroPSQpZuy",
        "outputId": "d6f46ec1-b9e7-47ce-fc30-a0fa896e70c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/msrflute/testing\n",
            "Downloading 1ISzp69JmaIJqBpQCX-JJ8-kVyUns8M7o into ./data/nlg_gru.zip... Done.\n",
            "Unzipping...Done.\n",
            "loading train_data.json\n",
            "counting train_data.json\n",
            "\n",
            "mkdir: cannot create directory ‘data/nlg_gru’: File exists\n",
            "loading train_data.json\n",
            "counting train_data.json\n",
            "\n",
            "loading val_data.json\n",
            "counting val_data.json\n",
            "\n",
            "mkdir: cannot create directory ‘data/nlg_gru’: File exists\n",
            "loading test_data.json\n",
            "counting test_data.json\n",
            "\n",
            "loading train_data.json\n",
            "counting train_data.json\n",
            "\n",
            "loading val_data.json\n",
            "counting val_data.json\n",
            "\n",
            "mkdir: cannot create directory ‘data’: File exists\n",
            "No files to process.\n",
            "mkdir: cannot create directory ‘data/mlm_bert’: File exists\n",
            "No files to process.\n",
            "mkdir: cannot create directory ‘data/mlm_bert’: File exists\n",
            "No files to process.\n",
            "mkdir: cannot create directory ‘data’: File exists\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
            "170499072it [00:13, 12759793.79it/s]                   \n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "100% 50/50 [01:22<00:00,  1.66s/it]\n",
            "100% 50/50 [00:00<00:00, 2257.04it/s]\n",
            "100% 50/50 [00:16<00:00,  3.04it/s]\n",
            "100% 50/50 [00:00<00:00, 4850.36it/s]\n",
            "mkdir: cannot create directory ‘data’: File exists\n",
            "100% 1000/1000 [00:03<00:00, 284.88it/s]\n",
            "100% 1000/1000 [00:00<00:00, 7339.02it/s]\n",
            "100% 1000/1000 [00:03<00:00, 277.46it/s]\n",
            "100% 1000/1000 [00:00<00:00, 6756.83it/s]\n",
            "/content/msrflute\n"
          ]
        }
      ],
      "source": [
        "%cd testing\n",
        "!python create_data.py --task nlg_gru\n",
        "!python create_data.py --task mlm_bert\n",
        "!python create_data.py --task classif_cnn\n",
        "!python create_data.py --task ecg_cnn\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfcKt0WtweSa"
      },
      "source": [
        "You don't HAVE to use these, as FLUTE also lets you customize your own datasets and experiments using a YAML file (would look something like the following):\n",
        "\n",
        "```yaml\n",
        "experiment_name: basic_example\n",
        "description: Basic example of AML config for submitting FLUTE jobs\n",
        "code:\n",
        "  local_path: .\n",
        "compute: azureml:Test\n",
        "environment:\n",
        "  image: pytorch/pytorch:1.9.0-cuda10.2-cudnn7-devel\n",
        "inputs:\n",
        "  data:\n",
        "    folder: azureml://datastores/data/paths/cifar\n",
        "    mode: rw_mount\n",
        "command: >\n",
        "  apt -y update &&\n",
        "  apt -y install openmpi-bin libopenmpi-dev openssh-client &&\n",
        "  python3 -m pip install --upgrade pip &&\n",
        "  python3 -m pip install -r requirements.txt &&\n",
        "  python -m torch.distributed.run --nproc_per_node=4 e2e_trainer.py\n",
        "  -outputPath=./outputs\n",
        "  -dataPath={inputs.data}\n",
        "  -task=classif_cnn\n",
        "  -config=./experiments/classif_cnn/config.yaml\n",
        "  -backend=nccl\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCEONrmBz5pm"
      },
      "source": [
        "### The `FedAvg` algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mha1ZXjJz8UJ"
      },
      "source": [
        "Now, if you saw the table above, you likely saw repeated mention of the `FedAvg` algorithm. To refresh, this is a popular algorithm for federated learning, a machine learning setting where the goal is to train a model across multiple decentralized edge devices or servers that hold local data samples. The basic idea of FedAvg is to train local models on each device or server for a number of epochs, and then send the models' parameters to a central server where they are averaged to obtain a global model. The process repeats until the model converges.\n",
        "\n",
        "Here's a more detailed breakdown of how the FedAvg algorithm works:\n",
        "\n",
        "1. **Initialization:** The central server initializes a global model with random parameters. This model is then distributed to all participating devices or servers.\n",
        "\n",
        "2. **Local Training:** Each device or server trains the received model on its local data for a certain number of epochs. This is done independently and concurrently on each device. The number of epochs can be a fixed number or can vary across devices.\n",
        "\n",
        "3. **Model Update Collection:** After local training, each device sends its locally updated model parameters back to the central server. The communication between the central server and the devices is typically done in a secure and privacy-preserving manner to ensure that the local data of each device remains confidential.\n",
        "\n",
        "4. **Global Model Update:** The central server averages the received model parameters to update the global model. This can be a simple arithmetic mean or a weighted average, where the weights are determined by the number of data samples on each device.\n",
        "\n",
        "5. **Iteration:** Steps 2-4 are repeated for a predetermined number of rounds or until the global model's performance converges.\n",
        "\n",
        "The goal of this process is to learn a model that performs well on the global distribution of data, without directly accessing the local data on each device. This makes federated learning particularly suitable for scenarios where data privacy is a concern, such as in healthcare or personal devices.\n",
        "\n",
        "One key assumption behind the FedAvg algorithm is that all devices follow the same data distribution (i.e., the data is identically and independently distributed or IID across devices). However, this assumption is often not met in practical federated learning settings, leading to a problem known as non-IID data. There have been many proposed solutions to address this issue, such as personalized federated learning and federated learning with model aggregation based on data distribution.\n",
        "\n",
        "Another challenge in federated learning is the communication efficiency. As each round of training requires devices to send their updated model parameters back to the server, this can consume a lot of network bandwidth and energy. Various techniques, such as model compression and communication-efficient federated learning algorithms, have been proposed to mitigate this problem.\n",
        "\n",
        "Overall, FedAvg provides a simple and effective framework for federated learning, but there are many ongoing research efforts to address its limitations and improve its performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwxmsqhRpNNJ"
      },
      "source": [
        "### Example FLUTE task #1: `nlg_gru`\n",
        "\n",
        "After this initial setup you can use your data for launching a local run. However the following instructions will be adapted to run `nlg_gru` task.\n",
        "\n",
        "This task involves training a GRU model on the preprocessed reddit dataset by [LEAF: A Benchmark for Federated Settings](https://arxiv.org/abs/1812.01097)\n",
        "\n",
        "For running this example, you need to first download and preprocess the data. Instructions can be found [here](https://github.com/microsoft/msrflute/tree/main/testing).\n",
        "\n",
        "Once the data is available you can run FLUTE from root as follows (using the GPU-only `NCCL` backend)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2rh805xnnJDr"
      },
      "outputs": [],
      "source": [
        "if GPU_COUNT >= 2:\n",
        "    !python -m torch.distributed.run \\\n",
        "        --nproc_per_node=4 e2e_trainer.py \\\n",
        "            -dataPath ./testing \\\n",
        "            -outputPath scratch \\\n",
        "            -config testing/hello_world_nlg_gru.yaml \\\n",
        "            -task nlg_gru \\\n",
        "            -backend nccl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5aB5Jeeqa6W"
      },
      "source": [
        "### Example FLUTE task #2: `mlm_bert`\n",
        "\n",
        "This experiment trains a BERT model using Federated learning.\n",
        "\n",
        "Like the previous example, it uses the preprocessed reddit dataset by [LEAF: A Benchmark for Federated Settings](https://arxiv.org/abs/1812.01097)\n",
        "\n",
        "For running this example, you need to first download and preprocess the data. Instructions can be found [here](https://github.com/microsoft/msrflute/tree/main/testing).\n",
        "\n",
        "Once the data is available you can run FLUTE from root as follows (using the GPU-only `NCCL` backend):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "I2AUQnwRrQy3"
      },
      "outputs": [],
      "source": [
        "if GPU_COUNT >= 2:\n",
        "    !python -m torch.distributed.run \\\n",
        "        --nproc_per_node=4 e2e_trainer.py \\\n",
        "            -dataPath ./testing \\\n",
        "            -outputPath scratch \\\n",
        "            -config testing/hello_world_mlm_bert.yaml \\\n",
        "            -task mlm_bert \\\n",
        "            -backend nccl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk4ry4Z_qfSd"
      },
      "source": [
        "### Example FLUTE task #3: `classif_cnn`\n",
        "\n",
        "For running this example, you need to first download and preprocess the data. Instructions can be found [here](https://github.com/microsoft/msrflute/tree/main/testing).\n",
        "\n",
        "This particular example trains on a divided-up version of the classic [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset for image classification.\n",
        "\n",
        "Once the data is available you can run FLUTE from root as follows (using the CPU-only `Gloo` backend):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nCEA5Ls0rQcF"
      },
      "outputs": [],
      "source": [
        "if GPU_COUNT >= 2:\n",
        "    !python -m torch.distributed.run \\\n",
        "        --nproc_per_node=4 e2e_trainer.py \\\n",
        "            -dataPath ./testing \\\n",
        "            -outputPath scratch \\\n",
        "            -config testing/hello_world_classif_cnn.yaml \\\n",
        "            -task classif_cnn \\\n",
        "            -backend gloo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qfXW4vBqhQR"
      },
      "source": [
        "### Example FLUTE task #4: `ecg_cnn`\n",
        "\n",
        "For running this example, you need to first download and preprocess the data. Instructions can be found [here](https://github.com/microsoft/msrflute/tree/main/testing).\n",
        "\n",
        "Once the data is available you can run FLUTE from root as follows (using the CPU-only `Gloo` backend):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pGtSq1esrQG1"
      },
      "outputs": [],
      "source": [
        "if GPU_COUNT >= 2:\n",
        "    !python -m torch.distributed.run \\\n",
        "        --nproc_per_node=4 e2e_trainer.py \\\n",
        "            -dataPath ./testing \\\n",
        "            -outputPath scratch \\\n",
        "            -config testing/hello_world_ecg_cnn.yaml \\\n",
        "            -task ecg_cnn \\\n",
        "            -backend gloo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DZEUVLhzhO4"
      },
      "source": [
        "# References and Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO5LxkjqmOQU"
      },
      "source": [
        "**FLUTE**\n",
        "- [FLUTE Overview — FLUTE  documentation](https://microsoft.github.io/msrflute/overview.html)\n",
        "- [Welcome to FLUTE documentation! — FLUTE  documentation](https://microsoft.github.io/msrflute/)\n",
        "- [microsoft/msrflute: Federated Learning Utilities and Tools for Experimentation](https://github.com/microsoft/msrflute)\n",
        "- [Project FLUTE - Microsoft Research](https://www.microsoft.com/en-us/research/project/project-flute/)\n",
        "- [Caldas, S., Duddu, S. M. K., Wu, P., Li, T., Konečný, J., McMahan, H. B., ... & Talwalkar, A. (2018). Leaf: A benchmark for federated settings. arXiv preprint arXiv:1812.01097.](https://arxiv.org/abs/1812.01097)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit ('3.9.0')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0 (default, Dec 11 2020, 03:26:52) \n[Clang 12.0.0 (clang-1200.0.32.21)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b6b7e97e50c754c7aee36d85160e6764033ec8a20165f676e018446c78d531c2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
