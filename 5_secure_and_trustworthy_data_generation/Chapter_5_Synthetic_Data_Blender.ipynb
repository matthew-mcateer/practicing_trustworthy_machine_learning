{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: Synthetic Data Blender\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Platform**           | **Link**                                                                                                                                                                                                                                                                                               | **Notes**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
    "|------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| _Local Folder_         | [Deep Dive Example: Synthetic Data Blender](5_secure_and_trustworthy_data_generation/Chapter_5_Synthetic_Data_Blender.ipynb)                                                                                                                                                                                                                                |    `5_secure_and_trustworthy_data_generation/`<br>`Chapter_5_Synthetic_Data_Blender.ipynb`<br>See the specific instructions<br>in the `README.md` for running this<br>particular notebook                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
    "| _Book Chapter_         | [Chapter 5: Secure and Trustworthy Data Generation](https://learning.oreilly.com/library/view/practicing-trustworthy-machine/9781098120269/ch05.html)                                                                                                                                                                                 | Ebook available from [O'Reilly](https://www.oreilly.com/library/view/practicing-trustworthy-machine/9781098120269/).<br>Physical book available from [Amazon](https://www.amazon.com/Practicing-Trustworthy-Machine-Learning-Transparent/dp/1098120272)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
    "| _GitHub_               | [![GitHub](https://img.shields.io/badge/-View%20on%20GitHub-181717?logo=github&logoColor=ffffff)](https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/5_secure_and_trustworthy_data_generation/Chapter_5_Synthetic_Data_Blender.ipynb)                                                                          | Please star on GitHub so others can<br>find this repo and get help with implenting<br>their trustworthy AI pipelines<br> [![GitHub forks](https://img.shields.io/github/forks/matthew-mcateer/practicing_trustworthy_machine_learning.svg?style=social&label=Fork&maxAge=2592000)](https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/network/) <br> [![GitHub stars](https://img.shields.io/github/stars/matthew-mcateer/practicing_trustworthy_machine_learning.svg?style=social&label=Star&maxAge=2592000)](https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/stargazers/) <br> [![GitHub watchers](https://img.shields.io/github/watchers/matthew-mcateer/practicing_trustworthy_machine_learning.svg?style=social&label=Watch&maxAge=2592000)](https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/watchers/) <br>[`@matthew-mcateer`](https://github.com/matthew-mcateer) [![GitHub followers](https://img.shields.io/github/followers/matthew-mcateer?style=social&label=Follow&maxAge=2592000)](https://github.com/matthew-mcateer?tab=followers)<br>[`@pruksmhc`](https://github.com/pruksmhc) [![GitHub followers](https://img.shields.io/github/followers/pruksmhc?style=social&label=Follow&maxAge=2592000)](https://github.com/pruksmhc?tab=followers)<br>[`@shubhobm`](https://github.com/shubhobm) [![GitHub followers](https://img.shields.io/github/followers/shubhobm?style=social&label=Follow&maxAge=2592000)](https://github.com/shubhobm?tab=followers)  |\n",
    "| _Colab_                | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/5_secure_and_trustworthy_data_generation/Chapter_5_Synthetic_Data_Blender.ipynb)                                                                         | This notebook requires docker<br>in order to use Blender 2.93.<br>Colab _not_ recommended                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
    "| _Kaggle_               | [ ![ Kaggle ]( https://kaggle.com/static/images/open-in-kaggle.svg ) ]( https://kaggle.com/kernels/welcome?src=https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/5_secure_and_trustworthy_data_generation/Chapter_5_Synthetic_Data_Blender.ipynb )                                                            | This notebook requires docker<br>in order to use Blender 2.93.<br>Kaggle _not_ recommended                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
    "| _Gradient_             | [ ![ Gradient ]( https://assets.paperspace.io/img/gradient-badge.svg ) ]( https://console.paperspace.com/github/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/5_secure_and_trustworthy_data_generation/Chapter_5_Synthetic_Data_Blender.ipynb )                                                                              | This notebook requires docker<br>in order to use Blender 2.93.<br>Gradient _not_ recommended                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
    "| _SageMaker Studio Lab_ | [![ Open In SageMaker Studio Lab ]( https://studiolab.sagemaker.aws/studiolab.svg ) ]( https://studiolab.sagemaker.aws/import/github/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/5_secure_and_trustworthy_data_generation/Chapter_5_Synthetic_Data_Blender.ipynb )                                                         | Recommend `ml.g4dn.xlarge` instance at minimum.<br>(alternatively, `g4dn.2xlarge` if using EC2 instance)<br>Make sure docker is installed<br>in order to use Blender 2.93.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
    "| _Binder_               | [ ![ Binder ]( https://mybinder.org/badge_logo.svg ) ]( https://mybinder.org/v2/gh/matthew-mcateer/practicing_trustworthy_machine_learning/HEAD?urlpath=https%3A%2F%2Fgithub.com%2Fmatthew-mcateer%2Fpracticing_trustworthy_machine_learning%2Fblob%2Fmain%2F5_secure_and_trustworthy_data_generation%2FChapter_5_Synthetic_Data_Blender.ipynb ) | This notebook requires docker<br>in order to use Blender 2.93.<br>Binder _not_ recommended                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
    "\n",
    "<!--\n",
    "Originally found on GitHub at https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/5_secure_and_trustworthy_data_generation/Chapter_5_Synthetic_Data_Blender.ipynb\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Installing dependencies { display-mode: \"form\" }\n",
    "%load_ext watermark\n",
    "%watermark -a \"Practicing Trustworthy machine Learning\" -u -d -v -m -p kubric,watermark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components of a Kubric Blender scene"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start by providing a very simple example of a Kubric scene.\n",
    "We'll create a scene with a renderer, along with objects such as a sphere and cube.\n",
    "We'll also add a light source and cameras.\n",
    "As an output, we'll get both the blender file as well as the rendered PNG files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import kubric as kb\n",
    "from kubric.renderer.blender import Blender as KubricRenderer\n",
    "\n",
    "logging.basicConfig(level=\"INFO\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every Kubric scene we will create a `kb.Scene` object.\n",
    "After we specify a resolution ($256 \\times 256$ in our case, though you can set it higher), we will attach a renderer to the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = kb.Scene(resolution=(256, 256))\n",
    "renderer = KubricRenderer(scene)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll populate our scene with a floor (represented by a flattened `kb.Cube`), a ball, a light source, and a camera perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene += kb.Cube(name=\"floor\", scale=(10, 10, 0.1), position=(0, 0, -0.1))\n",
    "scene += kb.Sphere(name=\"ball\", scale=1, position=(0, 0, 1.0))\n",
    "scene += kb.DirectionalLight(\n",
    "    name=\"sun\",\n",
    "    position=(-1, -0.5, 3),\n",
    "    look_at=(0, 0, 0),\n",
    "    intensity=1.5,\n",
    ")\n",
    "scene += kb.PerspectiveCamera(\n",
    "    name=\"camera\", position=(3, -1, 4), look_at=(0, 0, 1)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll then render this scene and save it to a blender file.\n",
    "\n",
    "Note: Kubric employs **Blender 2.93** (see [here](https://github.com/google-research/kubric/blob/01a08d274234f32f2adc4f7d5666b39490f953ad/docker/Blender.Dockerfile#L48)).\n",
    "\n",
    "If you want to inspect the generated `*.blend` scene file for interactive inspection (i.e. without needing to render the scene), please make sure you have installed the a Blender version **equal to or greater than 2.93**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "renderer.save_state(\"outputs/helloworld/ptml_helloworld.blend\")\n",
    "frame = renderer.render_still()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should produce a file that you can use to inspect the assets in Blender itself.\n",
    "\n",
    "![Example scene if you open the file in Blender directly](images/ptml_helloworld_blend.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `frame` object we have created is a dictionary with each key storing an image represented as a multi-dimensional `numpy.ndarray`.\n",
    "\n",
    "The frame types are:\n",
    "- RGBA (`'rgba'`): This is the closest to how human eyes would view the scene. Represented by 4-channel numpy arrays `[R, G, B, A]` with values in the range `[0, inf]`. This view can be saved with the `kb.write_png` method.\n",
    "- Depth (`'depth'`): This is for creating depth maps. Represented by 1-channel numpy arrays `[Depth]` with values in the range `[0, 10000000000.0]` (the value `1e10` is used for background / infinity).\n",
    "- Forward and Backward Flow(`'forward_flow'` & `'backward_flow'`): Blender exports forward and backward flow in a single image, and uses `(-delta_col, delta_row)` format, but Kubric prefers `(delta_row, delta_col)`.\n",
    "- Normal maps (`'normal'`): This is for creating normalized image outputs. Represented by 3-channel numpy arrays `[X, Y, Z]` with values in the range `[-1, 1]`.\n",
    "- Object Coordinates & Segmentation maps (`'object_coordinates'` & `'segmentation'`): Kubric stores the segmentation of Objects using two kinds of channels:\n",
    "    - index channels (`uint32`) specify the object index for a pixel\n",
    "    - alpha channels (`float32`) specify the corresponding mask value\n",
    "  \n",
    "  there may be many cryptomatte layers, which allows encoding a pixel as belonging to multiple objects at once (up to a maximum of # of layers many objects per pixel). In the EXR this is stored with 2 layers per RGBA image `(CryptoObject00, CryptoObject01, ...)` with RG being the first layer and BA being the second. So the R and B channels are `uint32` and the G and A channels are `float32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the output as pngs\n",
    "kb.write_png(frame[\"rgba\"], \"outputs/helloworld/ptml_helloworld.png\")\n",
    "kb.write_palette_png(\n",
    "    frame[\"segmentation\"], \"outputs/helloworld/ptml_helloworld_segmentation.png\"\n",
    ")\n",
    "scale = kb.write_scaled_png(\n",
    "    frame[\"depth\"], \"outputs/helloworld/ptml_helloworld_depth.png\"\n",
    ")\n",
    "logging.info(\"Depth scale: %s\", scale)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should produce a series of PNG files showing the rgba rendered scene, the segmentation map, and the depth map.\n",
    "\n",
    "<p float=\"left\">\n",
    "  <img src=\"images/ptml_helloworld.png\" width=\"200\" alt=\"Base image\" style=\"margin-right: 10px;\"/>\n",
    "  <img src=\"images/ptml_helloworld_segmentation.png\" width=\"200\" alt=\"Segmentation image\" style=\"margin-right: 10px;\"/> \n",
    "  <img src=\"images/ptml_helloworld_depth.png\" width=\"200\" alt=\"Depth image\" />\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KeyFraming Scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our initial hello-world example, we had a single image taken at a single angle.\n",
    "What if we want a larger sample of angles?\n",
    "In fact, we very well might want the camera to follow a continuous path.\n",
    "\n",
    "In animation and filmmaking, Keyframing is the process of indicating the beginning and end of a specific animation and allowing your editing program to fill in the transition between these two points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import kubric as kb\n",
    "import numpy as np\n",
    "from kubric.renderer.blender import Blender as KubricRenderer\n",
    "\n",
    "scene = kb.Scene(resolution=(256, 256), frame_start=1, frame_end=20)\n",
    "renderer = KubricRenderer(scene)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we'll populare the scene with a basic sphere, resting on a floor, with a perspective camera and a light source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene += kb.Sphere(\n",
    "    name=\"floor\", scale=1000, position=(0, 0, +1000), background=True\n",
    ")\n",
    "scene += kb.Cube(name=\"floor\", scale=(0.5, 0.7, 1.0), position=(0, 0, 1.1))\n",
    "scene += kb.PerspectiveCamera(\n",
    "    name=\"camera\", position=(3, -1, 4), look_at=(0, 0, 1)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this time we'll add Klevr-like lights to the scene for ambient illumination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene += kb.assets.utils.get_clevr_lights()\n",
    "scene.ambient_illumination = kb.Color(0.05, 0.05, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to keyframe a circular camera path around the object.\n",
    "Polar coordinates will work great for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_camera_position = (7.48113, -6.50764, 5.34367)\n",
    "r = np.sqrt(sum(a * a for a in original_camera_position))\n",
    "phi = np.arccos(original_camera_position[2] / r)\n",
    "theta = np.arccos(original_camera_position[0] / (r * np.sin(phi)))\n",
    "num_phi_values_per_theta = 1  # < only circular motion\n",
    "theta_change = (2 * np.pi) / (\n",
    "    (scene.frame_end - scene.frame_start) / num_phi_values_per_theta\n",
    ")\n",
    "for frame in range(scene.frame_start, scene.frame_end + 1):\n",
    "    i = frame - scene.frame_start\n",
    "    theta_new = (i // num_phi_values_per_theta) * theta_change + theta\n",
    "\n",
    "    # These values of (x, y, z) will lie on the same sphere as the original camera.\n",
    "    x = r * np.cos(theta_new) * np.sin(phi)\n",
    "    y = r * np.sin(theta_new) * np.sin(phi)\n",
    "    z = r * np.cos(phi)\n",
    "    z_shift_direction = (i % num_phi_values_per_theta) - 1\n",
    "    z = z + z_shift_direction * 1.2\n",
    "\n",
    "    scene.camera.position = (x, y, z)\n",
    "    scene.camera.look_at((0, 0, 0))\n",
    "    scene.camera.keyframe_insert(\"position\", frame)\n",
    "    scene.camera.keyframe_insert(\"quaternion\", frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll save the scene for a quick inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer.save_state(\"outputs/keyframing/ptml_keyframing.blend\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If when you load the file `ptml_keyframing.blend` in Blender, it looks like this...\n",
    "\n",
    "![Example scene if you open the file in Blender directly](images/ptml_keyframing_blend.png)\n",
    "\n",
    "... then you're on the right track and you can render the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stack = renderer.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we save the output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = kb.as_path(\"outputs/keyframing/\")\n",
    "kb.file_io.write_rgba_batch(data_stack[\"rgba\"], output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Blender's simulation capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blender isn't just for 3D rendering.\n",
    "It is also has a suite of tools for physics simulation.\n",
    "\n",
    "Setting up for physical simulation looks pretty similar to how we set up all our other fixed-camera-angle shots.\n",
    "\n",
    "However, for the simulation part, Kubric includes the Pybullet module.\n",
    "[Pybullet](https://pybullet.org/wordpress/) is a physics simulation tool for games, visual effects, robotics and reinforcement learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import kubric as kb\n",
    "from kubric.renderer.blender import Blender as KubricBlender\n",
    "from kubric.simulator.pybullet import PyBullet as KubricSimulator\n",
    "\n",
    "logging.basicConfig(level=\"WARNING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to our usual resolution-setting and populating the scene with generic solids, we will also include\n",
    "- the number of frames to render\n",
    "- the frame rate\n",
    "- the step-rate of the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = kb.Scene(resolution=(256, 256))\n",
    "scene.frame_end = 48  # < numbers of frames to render\n",
    "scene.frame_rate = 24  # < rendering framerate\n",
    "scene.step_rate = 240  # < simulation framerate\n",
    "renderer = KubricBlender(scene)\n",
    "simulator = KubricSimulator(scene)\n",
    "\n",
    "scene += kb.Cube(\n",
    "    name=\"floor\", scale=(3, 3, 0.1), position=(0, 0, -0.1), static=True\n",
    ")\n",
    "scene += kb.DirectionalLight(\n",
    "    name=\"sun\", position=(-1, -0.5, 3), look_at=(0, 0, 0), intensity=1.5\n",
    ")\n",
    "scene.camera = kb.PerspectiveCamera(\n",
    "    name=\"camera\", position=(2, -0.5, 4), look_at=(0, 0, 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to have our simulator randomly generate spheres within a given spawn region.\n",
    "\n",
    "This is similar to how in videogames one might encounter objects or sprites spawning in the same area of a game map.\n",
    "\n",
    "And once we set up the simulator, these objects aren't going to stay stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spawn_region = [[-1, -1, 0], [1, 1, 1]]\n",
    "rng = np.random.default_rng()\n",
    "for i in range(8):\n",
    "    velocity = rng.uniform([-1, -1, 0], [1, 1, 0])\n",
    "    material = kb.PrincipledBSDFMaterial(color=kb.random_hue_color(rng=rng))\n",
    "    sphere = kb.Sphere(scale=0.1, velocity=velocity, material=material)\n",
    "    scene += sphere\n",
    "    kb.move_until_no_overlap(sphere, simulator, spawn_region=spawn_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the simulator and store the keyframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simulator.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, we can finally render the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "renderer.save_state(\"outputs/simulation/ptml_simulator.blend\")\n",
    "frames_dict = renderer.render()\n",
    "kb.write_image_dict(frames_dict, \"outputs/simulation\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now have a series of images for 47 different time steps, as well as many different views of the same scene.\n",
    "\n",
    "For example, at time step 0, we have the following views for backward flow, forward flow, and normal maps are also generated.\n",
    "\n",
    "<p float=\"left\">\n",
    "  <img src=\"images/ptml_simulation_backward_flow_00000.png\" width=\"200\" alt=\"Backward optical flow\" style=\"margin-right: 10px;\"/>\n",
    "  <img src=\"images/ptml_simulation_forward_flow_00000.png\" width=\"200\" alt=\"forward optical flow\" style=\"margin-right: 10px;\"/> \n",
    "  <img src=\"images/ptml_simulation_normal_00000.png\" width=\"200\" alt=\"normal map\" />\n",
    "</p>\n",
    "\n",
    "We also have a views for the object coordinates, the RGBA view (i.e., the base image), and the segmentation map.\n",
    "\n",
    "<p float=\"left\">\n",
    "  <img src=\"images/ptml_simulation_object_coordinates_00000.png\" width=\"200\" alt=\"Object coordinates\" style=\"margin-right: 10px;\"/>\n",
    "  <img src=\"images/ptml_simulation_rgba_00000.png\" width=\"200\" alt=\"RGBA view\" style=\"margin-right: 10px;\"/> \n",
    "  <img src=\"images/ptml_simulation_segmentation_00000.png\" width=\"200\" alt=\"Segmentation map\" />\n",
    "</p>\n",
    "\n",
    "Not pictured is the depth map, which is just a single-channel `.tiff` file.\n",
    "And we have all 7 of these types of images for _ALL 48 frames_ of the simulation.\n",
    "\n",
    "As you can imagine, creating synthetic datasets for multiple modalities from the same scene can be much more efficient than hunting down your own real-world datasets.\n",
    "Just remember to make sure you've set up your Blender environment as best you can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References and Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kubric**\n",
    "\n",
    "- Kubrics GitHub: https://github.com/google-research/kubric\n",
    "- Kubric Documentation: https://kubric.readthedocs.io/en/latest/index.html\n",
    "- [Greff, Klaus, Francois Belletti, Lucas Beyer, Carl Doersch, Yilun Du, Daniel Duckworth, David J. Fleet et al. \"Kubric: A scalable dataset generator.\" In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 3749-3761. 2022.](https://openaccess.thecvf.com/content/CVPR2022/papers/Greff_Kubric_A_Scalable_Dataset_Generator_CVPR_2022_paper.pdf)\n",
    "\n",
    "**Blender**\n",
    "\n",
    "- [Blender 2.93 LTS Download Page](https://www.blender.org/download/releases/2-93/)\n",
    "\n",
    "**PyBullet**\n",
    "\n",
    "- PyBullet homepage: https://pybullet.org/wordpress/\n",
    "- GitHub repo: https://github.com/bulletphysics/bullet3"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b6b7e97e50c754c7aee36d85160e6764033ec8a20165f676e018446c78d531c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
