{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-RLwt28IRgF7"
      },
      "source": [
        "# Chapter 1: SMPC Example (Deprecated)\n",
        "\n",
        "| Chapter  | Colab   | Kaggle          | Gradient      | Studio Lab             | Binder             |\n",
        "|:---------|:--------|:----------------|:--------------|:-----------------------|:-------------------|\n",
        "| [Chapter 1: SMPC Example](1_privacy/deprecated/Chapter_1_SMPC_Example_DEPRECATED.ipynb)                         | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/1_privacy/deprecated/Chapter_1_SMPC_Example_DEPRECATED.ipynb)       | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/1_privacy/deprecated/Chapter_1_SMPC_Example_DEPRECATED.ipynb)       | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/1_privacy/deprecated/Chapter_1_SMPC_Example_DEPRECATED.ipynb)       | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/1_privacy/deprecated/Chapter_1_SMPC_Example_DEPRECATED.ipynb)       | [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/matthew-mcateer/practicing_trustworthy_machine_learning/HEAD?urlpath=https%3A%2F%2Fgithub.com%2Fmatthew-mcateer%2Fpracticing_trustworthy_machine_learning%2Fblob%2Fmain%2F1_privacy%2Fdeprecated%2FChapter_1_SMPC_Example_DEPRECATED.ipynb)              |\n",
        "\n",
        "<!--\n",
        "Originally found on GitHub at https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/1_privacy/deprecated/Chapter_1_SMPC_Example_DEPRECATED.ipynb\n",
        "-->\n",
        "\n",
        "\n",
        "The following is heavily based on an OpenMined tutorial written by [Ayoub Benaissa - Twitter: @y0uben11](https://twitter.com/y0uben11)\n",
        "\n",
        "```text\n",
        "This tutorial is currently optimized for running in a Docker container on a local machine.\n",
        "\n",
        "The tutorial that inspired this previously could run on multiple Google Colab instances.\n",
        "\n",
        "However, after Colab changed the accessibility of multiple runtimes, this is no longer the case.\n",
        "\n",
        "Specific instructions for the new Colab version will be added in the future.\n",
        "```\n",
        "\n",
        "To run this example, clone the [OpenMined/Pygrid](https://github.com/OpenMined/PyGrid/commit/048be4ac52a53b5ca947b920e41de9a9e76a532a) repo and start the two GridNodes by running\n",
        "\n",
        "```bash\n",
        "cd\n",
        "cd apps/node\n",
        "./run.sh --id ID --port 3000 --start_local_db\n",
        "```\n",
        "\n",
        "and\n",
        "\n",
        "```bash\n",
        "cd\n",
        "cd apps/node\n",
        "./run.sh --id ID --port 3001 --start_local_db\n",
        "```\n",
        "\n",
        "in separate terminals.\n",
        "\n",
        "Alternatively, you can use the colab notebooks\n",
        "\n",
        "- [SMPC_Mock_Node_1.ipynb](1_privacy/deprecated/Chapter_1_SMPC_Mock_Node_1.ipynb)\n",
        "- [SMPC_Mock_Node_2.ipynb](1_privacy/deprecated/Chapter_1_SMPC_Mock_Node_2.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4IGp3E3RjU0",
        "outputId": "10b549ef-dcb3-4382-8d0c-8701a2c59e43"
      },
      "outputs": [],
      "source": [
        "#@title PySyft & PyTorch Setup { display-mode: \"form\" }\n",
        "!pip -qq uninstall torch torchvision --y\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "except:\n",
        "    print(\"PyTorch not installed. Installing...\")\n",
        "    !pip -qq install torch==1.8.0\n",
        "\n",
        "    import torch\n",
        "    print(\"Torch version: \", torch.__version__ )\n",
        "    assert torch.__version__=='1.8.0', \"torch version is not 1.8.0, the version needed to make this run correctly\"\n",
        "\n",
        "!pip -qq install syft==0.2.9\n",
        "!pip -qq install crypten\n",
        "!pip -qq install loguru\n",
        "#!pip -qq install --upgrade --force-reinstall lz4\n",
        "#!pip -qq install --upgrade --force-reinstall websocket\n",
        "#!pip -qq install --upgrade --force-reinstall websockets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_jjjflCe6kA"
      },
      "outputs": [],
      "source": [
        "!pip -qq install watermark\n",
        "%load_ext watermark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "KW-1TC4JfPRw",
        "outputId": "8c5ddd7f-f8c2-49ca-c401-f985b0b90ca8"
      },
      "outputs": [],
      "source": [
        "%watermark -a \"Practicing Trustworthy machine Learning\" -u -d -v -m -p syft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqyAB6XpfPJF"
      },
      "outputs": [],
      "source": [
        "%watermark -a \"Practicing Trustworthy machine Learning\" -u -d -v -m -p syft,crypten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1OZulcPfN7P"
      },
      "outputs": [],
      "source": [
        "%watermark -a \"Practicing Trustworthy machine Learning\" -u -d -v -m -p syft,crypten,loguru,torch,torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmpN-OEvYH3a"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0uInwhfRiYE"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import crypten\n",
        "import syft\n",
        "from time import time\n",
        "from syft.frameworks.crypten.context import run_multiworkers\n",
        "from syft.grid.clients.data_centric_fl_client import DataCentricFLClient\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6f0BtjwRiJU"
      },
      "outputs": [],
      "source": [
        "!wget \"https://raw.githubusercontent.com/facebookresearch/CrypTen/b1466440bde4db3e6e1fcb1740584d35a16eda9e/tutorials/mnist_utils.py\" -O \"mnist_utils.py\"\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ox-ueitRiGd"
      },
      "outputs": [],
      "source": [
        "\n",
        "!python \"mnist_utils.py\" --option features --reduced 100 --binary\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5CfSXuIdXNf"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "torch.set_num_threads(1)\n",
        "hook = syft.TorchHook(torch)\n",
        "\n",
        "#from syft.workers.node_client import NodeClient # No module named 'syft.workers.node_client'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-eJtdjqRiDj"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Define an example network\n",
        "class ExampleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ExampleNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, padding=0)\n",
        "        self.fc1 = nn.Linear(16 * 12 * 12, 100)\n",
        "        self.fc2 = nn.Linear(100, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = F.relu(out)\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = out.view(-1, 16 * 12 * 12)\n",
        "        out = self.fc1(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAU6KKfCRiAa"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Syft workers\n",
        "print(\"[%] Connecting to workers ...\")\n",
        "ALICE = DataCentricFLClient(hook, \"ws://localhost:3000\")\n",
        "BOB = DataCentricFLClient(hook, \"ws://localhost:3001\")\n",
        "print(\"[+] Connected to workers\")\n",
        "\n",
        "print(\"[%] Sending labels and training data ...\")\n",
        "# Prepare and send labels\n",
        "label_eye = torch.eye(2)\n",
        "labels = torch.load(\"/tmp/train_labels.pth\")\n",
        "labels = labels.long()\n",
        "labels_one_hot = label_eye[labels]\n",
        "labels_one_hot.tag(\"labels\")\n",
        "al_ptr = labels_one_hot.send(ALICE)\n",
        "bl_ptr = labels_one_hot.send(BOB)\n",
        "\n",
        "# Prepare and send training data\n",
        "alice_train = torch.load(\"/tmp/alice_train.pth\").tag(\"alice_train\")\n",
        "at_ptr = alice_train.send(ALICE)\n",
        "bob_train = torch.load(\"/tmp/bob_train.pth\").tag(\"bob_train\")\n",
        "bt_ptr = bob_train.send(BOB)\n",
        "\n",
        "print(\"[+] Data ready\")\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXRa1d6bXmzU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initialize model\n",
        "dummy_input = torch.empty(1, 1, 28, 28)\n",
        "pytorch_model = ExampleNet()\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e86ff--bXmxL"
      },
      "outputs": [],
      "source": [
        "\n",
        "@run_multiworkers([ALICE, BOB], master_addr=\"127.0.0.1\", model=pytorch_model, dummy_input=dummy_input)\n",
        "def run_encrypted_training():\n",
        "    rank = crypten.communicator.get().get_rank()\n",
        "    # Load the labels\n",
        "    worker = syft.frameworks.crypten.get_worker_from_rank(rank)\n",
        "    labels_one_hot = worker.search(\"labels\")[0]\n",
        "    # Load data:\n",
        "    x_alice_enc = crypten.load(\"alice_train\", 0)\n",
        "    x_bob_enc = crypten.load(\"bob_train\", 1)\n",
        "    # Combine the feature sets: identical to Tutorial 3\n",
        "    x_combined_enc = crypten.cat([x_alice_enc, x_bob_enc], dim=2)\n",
        "    # Reshape to match the network architecture\n",
        "    x_combined_enc = x_combined_enc.unsqueeze(1)\n",
        "    # model is sent from the master worker\n",
        "    model.encrypt()\n",
        "    # Set train mode\n",
        "    model.train()\n",
        "    # Define a loss function\n",
        "    loss = crypten.nn.MSELoss()\n",
        "    # Define training parameters\n",
        "    learning_rate = 0.001\n",
        "    num_epochs = 2\n",
        "    batch_size = 10\n",
        "    num_batches = x_combined_enc.size(0) // batch_size\n",
        "\n",
        "    for i in range(num_epochs):\n",
        "        # Print once for readability\n",
        "        if rank == 0:\n",
        "            print(f\"Epoch {i} in progress:\")\n",
        "            pass\n",
        "\n",
        "        for batch in range(num_batches):\n",
        "            # define the start and end of the training mini-batch\n",
        "            start, end = batch * batch_size, (batch + 1) * batch_size\n",
        "            # construct AutogradCrypTensors out of training examples / labels\n",
        "            x_train = x_combined_enc[start:end]\n",
        "            y_batch = labels_one_hot[start:end]\n",
        "            y_train = crypten.cryptensor(y_batch, requires_grad=True)\n",
        "            # perform forward pass:\n",
        "            output = model(x_train)\n",
        "            loss_value = loss(output, y_train)\n",
        "            # set gradients to \"zero\"\n",
        "            model.zero_grad()\n",
        "            # perform backward pass:\n",
        "            loss_value.backward()\n",
        "            # update parameters\n",
        "            model.update_parameters(learning_rate)\n",
        "            # Print progress every batch:\n",
        "            batch_loss = loss_value.get_plain_text()\n",
        "            if rank == 0:\n",
        "                print(f\"\\tBatch {(batch + 1)} of {num_batches} Loss {batch_loss.item():.4f}\")\n",
        "\n",
        "    model.decrypt()\n",
        "    # printed contain all the printed strings during training\n",
        "    return printed, model\n",
        "     \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdB3NAMiXmuj"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"[%] Starting computation\")\n",
        "func_ts = time()\n",
        "result = run_encrypted_training()\n",
        "func_te = time()\n",
        "print(f\"[+] run_encrypted_training() took {int(func_te - func_ts)}s\")\n",
        "printed = result[0][0]\n",
        "model = result[0][1]\n",
        "print(printed)\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yi0MejkqXmr4"
      },
      "outputs": [],
      "source": [
        "\n",
        "cp = syft.VirtualWorker(hook=hook, id=\"cp\")\n",
        "model.fix_prec()\n",
        "model.share(ALICE, BOB, crypto_provider=cp)\n",
        "print(model)\n",
        "print(list(model.parameters())[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rT_nkoTkXmo7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit ('3.9.0')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0 (default, Dec 11 2020, 03:26:52) \n[Clang 12.0.0 (clang-1200.0.32.21)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "b6b7e97e50c754c7aee36d85160e6764033ec8a20165f676e018446c78d531c2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
