{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c8231b8e-5504-416b-b29b-eb2f8501aaf1",
      "metadata": {
        "id": "c8231b8e-5504-416b-b29b-eb2f8501aaf1"
      },
      "source": [
        "# Chapter 1: SMPC Example"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "9d42d1f4-befd-4723-97e7-3738ce237a6d",
      "metadata": {
        "id": "9d42d1f4-befd-4723-97e7-3738ce237a6d"
      },
      "source": [
        "\n",
        "\n",
        "| **Platform**           | **Link**                                                                                                                                                                                                                                                                                               | **Notes**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
        "|------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| _Local Folder_         | [Deep Dive Example: SMPC Example](1_privacy/Chapter_1_SMPC_Example.ipynb)                                                                                                                                                                                                                                |    `1_privacy/`<br>`Chapter_1_SMPC_Example.ipynb`<br>Recommend running locally                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
        "| _Book Chapter_         | [Chapter 1: Privacy](https://learning.oreilly.com/library/view/practicing-trustworthy-machine/9781098120269/ch01.html)                                                                                                                                                                                 | Ebook available from [O'Reilly](https://www.oreilly.com/library/view/practicing-trustworthy-machine/9781098120269/).<br>Physical book available from [Amazon](https://www.amazon.com/Practicing-Trustworthy-Machine-Learning-Transparent/dp/1098120272)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
        "| _GitHub_               | [![GitHub](https://img.shields.io/badge/-View%20on%20GitHub-181717?logo=github&logoColor=ffffff)](https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/1_privacy/Chapter_1_SMPC_Example.ipynb)                                                                          | Please star on GitHub so others can<br>find this repo and get help with implenting<br>their trustworthy AI pipelines<br> [![GitHub forks](https://img.shields.io/github/forks/matthew-mcateer/practicing_trustworthy_machine_learning.svg?style=social&label=Fork&maxAge=2592000)](https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/network/) <br> [![GitHub stars](https://img.shields.io/github/stars/matthew-mcateer/practicing_trustworthy_machine_learning.svg?style=social&label=Star&maxAge=2592000)](https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/stargazers/) <br> [![GitHub watchers](https://img.shields.io/github/watchers/matthew-mcateer/practicing_trustworthy_machine_learning.svg?style=social&label=Watch&maxAge=2592000)](https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/watchers/) <br>[`@matthew-mcateer`](https://github.com/matthew-mcateer) [![GitHub followers](https://img.shields.io/github/followers/matthew-mcateer?style=social&label=Follow&maxAge=2592000)](https://github.com/matthew-mcateer?tab=followers)<br>[`@pruksmhc`](https://github.com/pruksmhc) [![GitHub followers](https://img.shields.io/github/followers/pruksmhc?style=social&label=Follow&maxAge=2592000)](https://github.com/pruksmhc?tab=followers)<br>[`@shubhobm`](https://github.com/shubhobm) [![GitHub followers](https://img.shields.io/github/followers/shubhobm?style=social&label=Follow&maxAge=2592000)](https://github.com/shubhobm?tab=followers)  |\n",
        "| _Colab_                | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/1_privacy/Chapter_1_SMPC_Example.ipynb)                                                                         | [Hacks required](https://gist.github.com/mwufi/6718b30761cd109f9aff04c5144eb885) to<br>enable docker support<br>Enable GPU<br>(Colab Pro recommended)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
        "| _Kaggle_               | [ ![ Kaggle ]( https://kaggle.com/static/images/open-in-kaggle.svg ) ]( https://kaggle.com/kernels/welcome?src=https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/1_privacy/Chapter_1_SMPC_Example.ipynb )                                                            | Not recommended due<br>to lack of docker support                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
        "| _Gradient_             | [ ![ Gradient ]( https://assets.paperspace.io/img/gradient-badge.svg ) ]( https://console.paperspace.com/github/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/1_privacy/Chapter_1_SMPC_Example.ipynb )                                                                              | Enable GPU                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
        "| _SageMaker Studio Lab_ | [![ Open In SageMaker Studio Lab ]( https://studiolab.sagemaker.aws/studiolab.svg ) ]( https://studiolab.sagemaker.aws/import/github/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/1_privacy/Chapter_1_SMPC_Example.ipynb )                                                         | Recommend `ml.g4dn.xlarge` instance at minimum<br>(alternatively, `g4dn.2xlarge` if using EC2 instance)<br>See [Sagemaker docs](https://docs.aws.amazon.com/sagemaker/latest/dg/docker-containers.html)<br>regarding docker support                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
        "| _Binder_               | [ ![ Binder ]( https://mybinder.org/badge_logo.svg ) ]( https://mybinder.org/v2/gh/matthew-mcateer/practicing_trustworthy_machine_learning/HEAD?urlpath=https%3A%2F%2Fgithub.com%2Fmatthew-mcateer%2Fpracticing_trustworthy_machine_learning%2Fblob%2Fmain%2F1_privacy%2FChapter_1_SMPC_Example.ipynb ) | Not recommended due to<br>lack of Docker support                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
        "\n",
        "\n",
        "<!--\n",
        "Originally found on GitHub at https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/1_privacy/Chapter_1_SMPC_Example.ipynb\n",
        "-->\n",
        "\n",
        "\n",
        "The following is heavily based on OpenMined tutorials written by [Hrishikesh Kamath](https://twitter.com/kamathhrishi), [George Muraru](https://twitter.com/GeorgeMuraru), and [Th√©o Ryffel](http://twitter.com/theoryffel)\n",
        "\n",
        "\n",
        "This tutorial has seen the most changes out of any in the book. **The code for the early release version of the book [can be found in the `deprecated` folder](https://github.com/matthew-mcateer/practicing_trustworthy_machine_learning/blob/main/1_privacy/deprecated/Chapter_1_SMPC_Example_DEPRECATED.ipynb), and is conceptually identical to the tutorial here, but thanks to the `SyMPC` package this version provides a much gentler introduct to steps such as uploading one's data before any computation takes place.** The original code is still valid with the package versions that have been specified, but Google Colab no longer supports those specific tutorials.\n",
        "\n",
        "**UPDATE:** The `SyMPC` package no longer functions due to the removal of the `sympc-dev` branch of PySyft. As such, the dependencies for this tutorial are no longer resolvable. The dependencies for the specific versions of the packages used in the original tutorial are also no longer resolvable. We will provide an updated version of this tutorial in the future, though all the concepts described still apply."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "0497056d-252b-459a-ae0a-707d8b7af0e7",
      "metadata": {
        "id": "0497056d-252b-459a-ae0a-707d8b7af0e7"
      },
      "source": [
        "## ‚öôÔ∏è Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ZIGhddFCjfOc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIGhddFCjfOc",
        "outputId": "c9811891-62cd-4d8e-ba63-e4f601012976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Author: Practicing Trustworthy machine Learning\n",
            "\n",
            "Last updated: 2022-11-23\n",
            "\n",
            "Python implementation: CPython\n",
            "Python version       : 3.8.16\n",
            "IPython version      : 8.4.0\n",
            "\n",
            "syft   : 0.3.0\n",
            "loguru : 0.7.0\n",
            "torch  : 1.7.1\n",
            "sympc  : 0.5.0rc1.post0.dev92+g278a13d.dirty\n",
            "pandas : 1.8.1\n",
            "numpy  : 1.18.5\n",
            "crypten: 0.4.1\n",
            "\n",
            "Compiler    : GCC 11.3.0\n",
            "OS          : Linux\n",
            "Release     : 5.15.0-1036-aws\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 4\n",
            "Architecture: 64bit\n"
          ]
        }
      ],
      "source": [
        "#@title Checking environment\n",
        "%load_ext watermark\n",
        "%watermark -a \"Practicing Trustworthy machine Learning\" -u -d -v -m -p syft,loguru,torch,sympc,pandas,numpy,crypten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6b8a53a7-22a4-49bd-b2de-e9c112303a0e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b8a53a7-22a4-49bd-b2de-e9c112303a0e",
        "outputId": "6031d4d0-1771-420d-86b5-1d0cd8dc820d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fee9d9b9770>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "\n",
        "#Set a manual seed to maintain consistency\n",
        "torch.manual_seed(1337)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "8322cd06-4454-4236-a236-5008afb95955",
      "metadata": {
        "id": "8322cd06-4454-4236-a236-5008afb95955"
      },
      "source": [
        "## üóÇÔ∏è Data Loading and Processing for SMPC"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "64bfa0b8",
      "metadata": {},
      "source": [
        "Secure Multi-Party Computation (SMPC) is a subfield of cryptography that allows multiple parties to jointly compute a function over their inputs while keeping those inputs private. This is done by splitting the inputs into shares, and distributing them among the parties. The parties then perform computations on their shares, and share the results with each other. The parties can then combine the results to get the final result of the computation.\n",
        "\n",
        "This is an almost insultingly simple overview of a general class of protocols. Many of these are complex, or are based on assumptions that only apply in key situations.\n",
        "\n",
        "\n",
        "For the sake of our demonstration, we'll be training a regression network on the [Boston Housing Dataset](https://www.kaggle.com/datasets/altavish/boston-housing-dataset), and then running inference on the trained model using SMPC.\n",
        "\n",
        "The Boston housing dataset contains 506 observations and 14 variables.\n",
        "\n",
        "It also contains some missing values (which, if we are doing SMPC for real, we should expect to have to deal with varying levels of data quality).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a0fd28bf-1cb3-4733-84b7-7ed203e0b5b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0fd28bf-1cb3-4733-84b7-7ed203e0b5b9",
        "outputId": "11965954-6e14-409e-9cba-c98b5849a9cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-11-23 21:31:00--  https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49082 (48K) [application/x-httpd-php]\n",
            "Saving to: ‚Äòhousing.data‚Äô\n",
            "\n",
            "housing.data        100%[===================>]  47.93K   157KB/s    in 0.3s    \n",
            "\n",
            "2022-11-23 21:31:02 (157 KB/s) - ‚Äòhousing.data‚Äô saved [49082/49082]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download Boston housing dataset\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "6b259fbf",
      "metadata": {},
      "source": [
        "Once downloaded, we can then import the dataset in CSV format and add the data headers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "19f5c773-a0b8-41f8-8a34-3556cfa3ddf8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19f5c773-a0b8-41f8-8a34-3556cfa3ddf8"
      },
      "outputs": [],
      "source": [
        "# Import dataset and add headers\n",
        "dataset = pd.read_csv(\n",
        "    \"housing.data\",\n",
        "    delim_whitespace=True,\n",
        "    names=[\n",
        "        \"crim\",\n",
        "        \"zn\",\n",
        "        \"indus\",\n",
        "        \"chas\",\n",
        "        \"nox\",\n",
        "        \"rm\",\n",
        "        \"age\",\n",
        "        \"dis\",\n",
        "        \"rad\",\n",
        "        \"tax\",\n",
        "        \"ptratio\",\n",
        "        \"black\",\n",
        "        \"lstat\",\n",
        "        \"medv\",\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ac225885",
      "metadata": {},
      "source": [
        "While we may not necessarily have the opportunity in a SMPC scenario (depending on the domain, this might be either impossible or strongly discouraged), we will look at our data to get a sense of what we're working with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "eb168348-681c-45e1-9988-7b8525262ce5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eb168348-681c-45e1-9988-7b8525262ce5",
        "outputId": "e87752f5-88d8-42bb-9c69-d4b54d1bc3c0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1d3a5575-73ab-4062-afe4-fa1ec6bc0182\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>crim</th>\n",
              "      <th>zn</th>\n",
              "      <th>indus</th>\n",
              "      <th>chas</th>\n",
              "      <th>nox</th>\n",
              "      <th>rm</th>\n",
              "      <th>age</th>\n",
              "      <th>dis</th>\n",
              "      <th>rad</th>\n",
              "      <th>tax</th>\n",
              "      <th>ptratio</th>\n",
              "      <th>black</th>\n",
              "      <th>lstat</th>\n",
              "      <th>medv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d3a5575-73ab-4062-afe4-fa1ec6bc0182')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d3a5575-73ab-4062-afe4-fa1ec6bc0182 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d3a5575-73ab-4062-afe4-fa1ec6bc0182');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      crim    zn  indus  chas    nox     rm   age     dis  rad    tax  \\\n",
              "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
              "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
              "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
              "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
              "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
              "\n",
              "   ptratio   black  lstat  medv  \n",
              "0     15.3  396.90   4.98  24.0  \n",
              "1     17.8  396.90   9.14  21.6  \n",
              "2     17.8  392.83   4.03  34.7  \n",
              "3     18.7  394.63   2.94  33.4  \n",
              "4     18.7  396.90   5.33  36.2  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "a306b24a",
      "metadata": {},
      "source": [
        "The data is looking good, though we should also make sure we're going through the proper preprocessing steps.\n",
        "\n",
        "For starters, we want to make sure we're selecting the right column to predict by splitting data into the features and target variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b9d2ee8c-3e09-4935-b3a4-05a1defec19a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9d2ee8c-3e09-4935-b3a4-05a1defec19a"
      },
      "outputs": [],
      "source": [
        "features = dataset.drop(\"medv\", axis=1)\n",
        "targets = dataset[\"medv\"]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "7d3aa007",
      "metadata": {},
      "source": [
        "For the predictive features, let's make sure we're normalizing the data to reduce the impact of outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bbc0acf2-23d3-43fe-ade2-008767060142",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbc0acf2-23d3-43fe-ade2-008767060142"
      },
      "outputs": [],
      "source": [
        "features = features.apply(\n",
        "    lambda x: (x - x.mean()) / x.std()\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "db946850",
      "metadata": {},
      "source": [
        "Now, we should have the data features we want to input into our model..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d8512b67-5ebe-4762-8286-360c43a660f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "d8512b67-5ebe-4762-8286-360c43a660f4",
        "outputId": "b8775701-3dbf-4d14-ad1f-90327728b73c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2a796c93-5723-4a41-99fb-be558f6388fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>crim</th>\n",
              "      <th>zn</th>\n",
              "      <th>indus</th>\n",
              "      <th>chas</th>\n",
              "      <th>nox</th>\n",
              "      <th>rm</th>\n",
              "      <th>age</th>\n",
              "      <th>dis</th>\n",
              "      <th>rad</th>\n",
              "      <th>tax</th>\n",
              "      <th>ptratio</th>\n",
              "      <th>black</th>\n",
              "      <th>lstat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.419367</td>\n",
              "      <td>0.284548</td>\n",
              "      <td>-1.286636</td>\n",
              "      <td>-0.272329</td>\n",
              "      <td>-0.144075</td>\n",
              "      <td>0.413263</td>\n",
              "      <td>-0.119895</td>\n",
              "      <td>0.140075</td>\n",
              "      <td>-0.981871</td>\n",
              "      <td>-0.665949</td>\n",
              "      <td>-1.457558</td>\n",
              "      <td>0.440616</td>\n",
              "      <td>-1.074499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.416927</td>\n",
              "      <td>-0.487240</td>\n",
              "      <td>-0.592794</td>\n",
              "      <td>-0.272329</td>\n",
              "      <td>-0.739530</td>\n",
              "      <td>0.194082</td>\n",
              "      <td>0.366803</td>\n",
              "      <td>0.556609</td>\n",
              "      <td>-0.867024</td>\n",
              "      <td>-0.986353</td>\n",
              "      <td>-0.302794</td>\n",
              "      <td>0.440616</td>\n",
              "      <td>-0.491953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.416929</td>\n",
              "      <td>-0.487240</td>\n",
              "      <td>-0.592794</td>\n",
              "      <td>-0.272329</td>\n",
              "      <td>-0.739530</td>\n",
              "      <td>1.281446</td>\n",
              "      <td>-0.265549</td>\n",
              "      <td>0.556609</td>\n",
              "      <td>-0.867024</td>\n",
              "      <td>-0.986353</td>\n",
              "      <td>-0.302794</td>\n",
              "      <td>0.396035</td>\n",
              "      <td>-1.207532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.416338</td>\n",
              "      <td>-0.487240</td>\n",
              "      <td>-1.305586</td>\n",
              "      <td>-0.272329</td>\n",
              "      <td>-0.834458</td>\n",
              "      <td>1.015298</td>\n",
              "      <td>-0.809088</td>\n",
              "      <td>1.076671</td>\n",
              "      <td>-0.752178</td>\n",
              "      <td>-1.105022</td>\n",
              "      <td>0.112920</td>\n",
              "      <td>0.415751</td>\n",
              "      <td>-1.360171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.412074</td>\n",
              "      <td>-0.487240</td>\n",
              "      <td>-1.305586</td>\n",
              "      <td>-0.272329</td>\n",
              "      <td>-0.834458</td>\n",
              "      <td>1.227362</td>\n",
              "      <td>-0.510674</td>\n",
              "      <td>1.076671</td>\n",
              "      <td>-0.752178</td>\n",
              "      <td>-1.105022</td>\n",
              "      <td>0.112920</td>\n",
              "      <td>0.440616</td>\n",
              "      <td>-1.025487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>-0.412820</td>\n",
              "      <td>-0.487240</td>\n",
              "      <td>0.115624</td>\n",
              "      <td>-0.272329</td>\n",
              "      <td>0.157968</td>\n",
              "      <td>0.438881</td>\n",
              "      <td>0.018654</td>\n",
              "      <td>-0.625178</td>\n",
              "      <td>-0.981871</td>\n",
              "      <td>-0.802418</td>\n",
              "      <td>1.175303</td>\n",
              "      <td>0.386834</td>\n",
              "      <td>-0.417734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>-0.414839</td>\n",
              "      <td>-0.487240</td>\n",
              "      <td>0.115624</td>\n",
              "      <td>-0.272329</td>\n",
              "      <td>0.157968</td>\n",
              "      <td>-0.234316</td>\n",
              "      <td>0.288648</td>\n",
              "      <td>-0.715931</td>\n",
              "      <td>-0.981871</td>\n",
              "      <td>-0.802418</td>\n",
              "      <td>1.175303</td>\n",
              "      <td>0.440616</td>\n",
              "      <td>-0.500355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>-0.413038</td>\n",
              "      <td>-0.487240</td>\n",
              "      <td>0.115624</td>\n",
              "      <td>-0.272329</td>\n",
              "      <td>0.157968</td>\n",
              "      <td>0.983986</td>\n",
              "      <td>0.796661</td>\n",
              "      <td>-0.772919</td>\n",
              "      <td>-0.981871</td>\n",
              "      <td>-0.802418</td>\n",
              "      <td>1.175303</td>\n",
              "      <td>0.440616</td>\n",
              "      <td>-0.982076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>-0.407361</td>\n",
              "      <td>-0.487240</td>\n",
              "      <td>0.115624</td>\n",
              "      <td>-0.272329</td>\n",
              "      <td>0.157968</td>\n",
              "      <td>0.724955</td>\n",
              "      <td>0.736268</td>\n",
              "      <td>-0.667776</td>\n",
              "      <td>-0.981871</td>\n",
              "      <td>-0.802418</td>\n",
              "      <td>1.175303</td>\n",
              "      <td>0.402826</td>\n",
              "      <td>-0.864446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>-0.414590</td>\n",
              "      <td>-0.487240</td>\n",
              "      <td>0.115624</td>\n",
              "      <td>-0.272329</td>\n",
              "      <td>0.157968</td>\n",
              "      <td>-0.362408</td>\n",
              "      <td>0.434302</td>\n",
              "      <td>-0.612640</td>\n",
              "      <td>-0.981871</td>\n",
              "      <td>-0.802418</td>\n",
              "      <td>1.175303</td>\n",
              "      <td>0.440616</td>\n",
              "      <td>-0.668397</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>506 rows √ó 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a796c93-5723-4a41-99fb-be558f6388fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2a796c93-5723-4a41-99fb-be558f6388fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2a796c93-5723-4a41-99fb-be558f6388fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         crim        zn     indus      chas       nox        rm       age  \\\n",
              "0   -0.419367  0.284548 -1.286636 -0.272329 -0.144075  0.413263 -0.119895   \n",
              "1   -0.416927 -0.487240 -0.592794 -0.272329 -0.739530  0.194082  0.366803   \n",
              "2   -0.416929 -0.487240 -0.592794 -0.272329 -0.739530  1.281446 -0.265549   \n",
              "3   -0.416338 -0.487240 -1.305586 -0.272329 -0.834458  1.015298 -0.809088   \n",
              "4   -0.412074 -0.487240 -1.305586 -0.272329 -0.834458  1.227362 -0.510674   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "501 -0.412820 -0.487240  0.115624 -0.272329  0.157968  0.438881  0.018654   \n",
              "502 -0.414839 -0.487240  0.115624 -0.272329  0.157968 -0.234316  0.288648   \n",
              "503 -0.413038 -0.487240  0.115624 -0.272329  0.157968  0.983986  0.796661   \n",
              "504 -0.407361 -0.487240  0.115624 -0.272329  0.157968  0.724955  0.736268   \n",
              "505 -0.414590 -0.487240  0.115624 -0.272329  0.157968 -0.362408  0.434302   \n",
              "\n",
              "          dis       rad       tax   ptratio     black     lstat  \n",
              "0    0.140075 -0.981871 -0.665949 -1.457558  0.440616 -1.074499  \n",
              "1    0.556609 -0.867024 -0.986353 -0.302794  0.440616 -0.491953  \n",
              "2    0.556609 -0.867024 -0.986353 -0.302794  0.396035 -1.207532  \n",
              "3    1.076671 -0.752178 -1.105022  0.112920  0.415751 -1.360171  \n",
              "4    1.076671 -0.752178 -1.105022  0.112920  0.440616 -1.025487  \n",
              "..        ...       ...       ...       ...       ...       ...  \n",
              "501 -0.625178 -0.981871 -0.802418  1.175303  0.386834 -0.417734  \n",
              "502 -0.715931 -0.981871 -0.802418  1.175303  0.440616 -0.500355  \n",
              "503 -0.772919 -0.981871 -0.802418  1.175303  0.440616 -0.982076  \n",
              "504 -0.667776 -0.981871 -0.802418  1.175303  0.402826 -0.864446  \n",
              "505 -0.612640 -0.981871 -0.802418  1.175303  0.440616 -0.668397  \n",
              "\n",
              "[506 rows x 13 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "8f325526",
      "metadata": {},
      "source": [
        "...as well as the targets we want to predict."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9977732c-e320-4942-9d2a-8776f7664773",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9977732c-e320-4942-9d2a-8776f7664773",
        "outputId": "45937dfe-1375-4961-e0dd-1d98d6f7697b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      24.0\n",
              "1      21.6\n",
              "2      34.7\n",
              "3      33.4\n",
              "4      36.2\n",
              "       ... \n",
              "501    22.4\n",
              "502    20.6\n",
              "503    23.9\n",
              "504    22.0\n",
              "505    11.9\n",
              "Name: medv, Length: 506, dtype: float64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "targets"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "117d6cf0",
      "metadata": {},
      "source": [
        "Since we'll be using PyTorch, we should convert our data into tensors that PyTorch can use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ffc8740e-2d03-4846-9218-27c7560cbf66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffc8740e-2d03-4846-9218-27c7560cbf66"
      },
      "outputs": [],
      "source": [
        "features = torch.tensor(features.values.astype(np.float32))\n",
        "targets = torch.tensor(targets.values.astype(np.float32))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "e5fdfb10",
      "metadata": {},
      "source": [
        "We'll define our aruments for training, such as the batch size, epochs, train/test split, and learning rate.\n",
        "\n",
        "Normally we'd put more effort into creating callbacks that could optimize the relevant hyperparameters on the fly, but we're making the training phase as simple as possible to illustrate that the special sauce is coming at the inference instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6fa09fa1-7915-43ca-8ddd-59c8a2ffc8d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fa09fa1-7915-43ca-8ddd-59c8a2ffc8d4"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "epochs = 300\n",
        "train_test_split = 0.8\n",
        "lr = 0.001"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "a5885840",
      "metadata": {},
      "source": [
        "We will split the dataset into the train and test slices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "baf817be-819d-4f97-bdc8-46246613ccc5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baf817be-819d-4f97-bdc8-46246613ccc5"
      },
      "outputs": [],
      "source": [
        "train_indices = int(len(features) * train_test_split)\n",
        "\n",
        "train_x = features[:train_indices]\n",
        "train_y = targets[:train_indices]\n",
        "\n",
        "test_x = features[train_indices + 1 :]\n",
        "test_y = targets[train_indices + 1 :]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "bb3df87d",
      "metadata": {},
      "source": [
        "And we will divide the dataset into branches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "88384814-d4f6-45ff-8b40-206daecfba04",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88384814-d4f6-45ff-8b40-206daecfba04"
      },
      "outputs": [],
      "source": [
        "def get_batches(X, y):\n",
        "    batches = []\n",
        "    for index in range(0, len(train_x) + 1, batch_size):\n",
        "        batches.append((X[index : index + batch_size], y[index : index + batch_size]))\n",
        "\n",
        "    return batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "bd48a83c-3c96-44c9-9bb0-b7f481b92cd1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd48a83c-3c96-44c9-9bb0-b7f481b92cd1"
      },
      "outputs": [],
      "source": [
        "train_batches = get_batches(train_x, train_y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "xdXSSxfAhmoh",
      "metadata": {
        "id": "xdXSSxfAhmoh"
      },
      "source": [
        "## üóùÔ∏è Plaintext Training"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "79d5cf10",
      "metadata": {},
      "source": [
        "We will demonstrate SMPC as it pertains to running inference on an already-trained model.\n",
        "We will use a toy linear regression model (see Chapter 3 for more on model explainability) on a toy housing dataset.\n",
        "\n",
        "For starters, let's import the PySyft library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "71dea119-df91-4012-a9a3-48aaa978db25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71dea119-df91-4012-a9a3-48aaa978db25"
      },
      "outputs": [],
      "source": [
        "import syft as sy\n",
        "sy.logger.remove()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d22d4368",
      "metadata": {},
      "source": [
        "Next, we define a basic linear regression model.\n",
        "\n",
        "This behaves just like any other `nn.Module` network we'd definine in PyTorch save for two key differences:\n",
        "\n",
        "1. We replace the `nn.Module` with `sy.Module`.\n",
        "2. We wrap up the reference to pytorch itself with the `torch_ref` argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ce850fb7-b70f-482c-955c-a86766e5a692",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce850fb7-b70f-482c-955c-a86766e5a692"
      },
      "outputs": [],
      "source": [
        "class LinearSyNet(sy.Module):\n",
        "    def __init__(self, torch_ref):\n",
        "        super(LinearSyNet, self).__init__(torch_ref=torch_ref)\n",
        "        self.fc1 = self.torch_ref.nn.Linear(13,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        return x\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "3b1c333b",
      "metadata": {},
      "source": [
        "Next we initialize our `model`, along with the optimizer and loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "31787a2f-b85c-4e1f-93c8-6a44ab21523f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31787a2f-b85c-4e1f-93c8-6a44ab21523f"
      },
      "outputs": [],
      "source": [
        "model = LinearSyNet(torch)\n",
        "loss_function = torch.nn.MSELoss(reduction='mean') \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "417bb1b7",
      "metadata": {},
      "source": [
        "And we can run our standard Stochastic Gradient Descent training loop.\n",
        "\n",
        "For a dataset this simple we're not even really bothering with features like momentum."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "6Hplaaq-hvqh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Hplaaq-hvqh",
        "outputId": "7dea306f-3048-4347-e3df-bbd26fbf2067"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/300  Running Loss : 998.8542400885754 and test loss: 385.4494185937673\n",
            "Epoch 50/300  Running Loss : 62.82259386625583 and test loss: 113.30346797719565\n",
            "Epoch 100/300  Running Loss : 53.1354183670673 and test loss: 57.561960747373489\n",
            "Epoch 150/300  Running Loss : 40.82360264512523 and test loss: 31.9676642938053\n",
            "Epoch 200/300  Running Loss : 39.0269033569808 and test loss: 24.6837654675415\n",
            "Epoch 250/300  Running Loss : 37.26858443477006 and test loss: 21.7789115590072\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for index in range(0, len(train_batches)):\n",
        "        \n",
        "        outputs = model(train_batches[index][0]).reshape([-1])\n",
        "        loss = loss_function(outputs, train_batches[index][1])\n",
        "        running_loss += loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    test_accuracy = loss_function(model(test_x).reshape([-1]), test_y)\n",
        "    if (epoch % 50) == 0:\n",
        "        print(\n",
        "            (\n",
        "                f\"Epoch {epoch}/{epochs}  \"\n",
        "                f\"Running Loss : {running_loss.item()/batch_size} and \"\n",
        "                f\"test loss: {test_accuracy.item()}\"\n",
        "            )\n",
        "        )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "BwZg2Q_wh6gY",
      "metadata": {
        "id": "BwZg2Q_wh6gY"
      },
      "source": [
        "## üîì Plaintext Inference"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "48770a56",
      "metadata": {},
      "source": [
        "Before we run encrypted inference on our model, we want to have a baseline for comparison.\n",
        "\n",
        "If you're running SMPC in real-life, then chances are you're running it on a network.\n",
        "\n",
        "Distributed systems engineering is very unforgiving when it comes to increasing the runtime of your code.\n",
        "\n",
        "For this reason, we'll make sure to include an unencrypted inference baseline to compare against in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "7021f638-9e2a-48ec-8524-629af6d5d32f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7021f638-9e2a-48ec-8524-629af6d5d32f"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "# Perform inference in plaintext\n",
        "plaintext_predictions = model(test_x).reshape([-1])\n",
        "end_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "afb7acbc-35a9-415e-806d-93d16a442745",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afb7acbc-35a9-415e-806d-93d16a442745",
        "outputId": "042a3d87-495a-41bb-e7a1-af28c2d0c87e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plaintext (Local) prediction:\n",
            "MSE Loss:  21.778203758424003\n",
            "Inference time:  0.0007644155007102572 s\n"
          ]
        }
      ],
      "source": [
        "print(\"Plaintext (Local) prediction:\")\n",
        "print(\"MSE Loss: \", loss_function(plaintext_predictions, test_y).item())\n",
        "print(\"Inference time: \", str(end_time - start_time), \"s\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c539f7f7",
      "metadata": {},
      "source": [
        "Now we can run inference over our secure multi-party computation network."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "LYPizfquiEM1",
      "metadata": {
        "id": "LYPizfquiEM1"
      },
      "source": [
        "## üîê Encrypted Inference"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "7020acb5",
      "metadata": {},
      "source": [
        "This is where we will import the `sympc` library.\n",
        "This library is a wrapper on top of PySyft that allows for SMPC.\n",
        "More importantly, it contains code for a variety of SMPC protocols for varying levels of network sizes and network trust."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "8aafa611-ed6c-45b2-8f7e-f12905585184",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aafa611-ed6c-45b2-8f7e-f12905585184"
      },
      "outputs": [],
      "source": [
        "#SyMPC imports required for encrypted inference\n",
        "import sympc\n",
        "from sympc.session import Session\n",
        "from sympc.session import SessionManager\n",
        "from sympc.tensor import MPCTensor,ShareTensorPointer\n",
        "from sympc.protocol import ABY3,beaver,Falcon,FSS,spdz"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "2555a784",
      "metadata": {},
      "source": [
        "The `MPCTensor` class is the tensor that holds reference to the shares owned by the different parties.\n",
        "The `Session` is a key object that stores many information about the current computation, including a reference to the parties involved.\n",
        "\n",
        "We will create a utility function that spins up an arbitrary number of PySyft `VirtualMachine` workers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "946ac3d9-605b-496a-b4f8-6b6a91faa9ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "946ac3d9-605b-496a-b4f8-6b6a91faa9ec"
      },
      "outputs": [],
      "source": [
        "def get_clients(n_parties: int) -> list[sy.VirtualMachine]:\n",
        "    \"\"\"Generate required number of syft clients and return them.\n",
        "    \"\"\"\n",
        "\n",
        "    parties = []\n",
        "    for index in range(n_parties):\n",
        "        parties.append(\n",
        "            sy.VirtualMachine(name=\"worker\" + str(index)).get_root_client()\n",
        "        )\n",
        "\n",
        "    return parties"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "668d645d",
      "metadata": {},
      "source": [
        "We will also make sure to effectively split up our data into a number of chunks equal to the number of parties in our SMPC network and distribute it appropriately.\n",
        "\n",
        "We have different ways to do this and all of them deal with `MPCTensor`, an orchestator that wants to do computation on data it does not see."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "d1a5fd85-66fb-450d-a8d5-dc8c2661656c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1a5fd85-66fb-450d-a8d5-dc8c2661656c"
      },
      "outputs": [],
      "source": [
        "def split_send(data: MPCTensor, session: Session) -> list[ShareTensorPointer]:\n",
        "    \"\"\"Splits data into number of chunks equal to number of\n",
        "    parties and distributes it to respective parties.\n",
        "    \"\"\"\n",
        "    data_pointers = []\n",
        "\n",
        "    split_size = int(len(data) / len(session.parties)) + 1\n",
        "    for index in range(0, len(session.parties)):\n",
        "        ptr = data[index * split_size : index * split_size + split_size].share(\n",
        "            session=session\n",
        "        )\n",
        "        data_pointers.append(ptr)\n",
        "\n",
        "    return data_pointers\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "bf325bcd",
      "metadata": {},
      "source": [
        "We will then create our function for inference.\n",
        "This is the crucial component as which protocol and which settings we use will heavily depend on\n",
        "\n",
        "1. The mathematical operations we want to perform.\n",
        "2. The number of parties involved.\n",
        "3. The trust level between the parties (and thus the security level we need).\n",
        "\n",
        "SyMPC supports several protocols that one might find handy in different situations.\n",
        "\n",
        "- `Falcon`\n",
        "    - Our main protocol of interest, due to its ability to be tuned depending on the level of trust in the network. Falcon uses 2-out-of-3 sharing where each party recieves two shares allowing 2 parties to reconstruct a secret without other party knowing. Thus, it is fast and secure for 3 participants, but it's not really scalable beyond 3. Falcon also assumes that majority of parties are honest (2 in this case).\n",
        "    - Paper: [FALCON: Honest-Majority Maliciously Secure Framework for Private Deep Learning](https://arxiv.org/abs/2004.02229) \n",
        "    - OpenMined/SyMPC Implementation: [code](https://github.com/OpenMined/SyMPC/blob/main/src/sympc/protocol/falcon/falcon.py)\n",
        "- `ABY3`:\n",
        "    - Another MPC framework for Machine learning.\n",
        "    - Paper: [ABY3 : A Mixed Protocol Framework for Machine Learning](https://eprint.iacr.org/2018/403.pdf) \n",
        "    - OpenMined/SyMPC Implementation: [code](https://github.com/OpenMined/SyMPC/blob/main/src/sympc/protocol/aby3/aby3.py)\n",
        "- `Function Secret Sharing (FSS)`:\n",
        "    - Securely works for MPC involving two parties. Distributes a single share of the data to both parties, and requires both parties to reconstruct the data.\n",
        "    - Paper: [ARIANN: Low-Interaction Privacy-Preserving Deep Learning via Function Secret Sharing](https://arxiv.org/abs/2006.04593) \n",
        "    - OpenMined/SyMPC Implementation: [code](https://github.com/OpenMined/SyMPC/blob/main/src/sympc/protocol/fss/fss.py)\n",
        "- `SPDZ`:\n",
        "    - Pronounced \"speedz\", this protocol can be extended to an arbitrary number of parties in an SMPC network, and is secure against an active adversary corrupting up to N-1 of the N participants. SPDZ and FSS distributes a single share to every party requiring shares from all parties for reconstruction ensuring no parties could collude. Currently SyMPC provides support for SPDZ and FSS with semi-honest security guarantee. This allows parties to tamper with shares leading to incorrect results.\n",
        "    - Paper: [Multiparty Computation from Somewhat Homomorphic Encryption](https://link.springer.com/chapter/10.1007/978-3-642-32009-5_38) \n",
        "    - OpenMined/SyMPC Implementation: [code]()\n",
        "- `Beaver Triples`:\n",
        "    - One of the earliest protocols for SMPC (created back in 1992).\n",
        "    - Paper: [Efficient multiparty protocols using circuit randomization](https://link.springer.com/content/pdf/10.1007/3-540-46766-1_34.pdf) \n",
        "    - OpenMined/SyMPC Implementation: [code](https://github.com/OpenMined/SyMPC/blob/main/src/sympc/protocol/beaver/beaver.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "3cd7ad1f-dce7-4d7b-8b94-2f729fb372a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cd7ad1f-dce7-4d7b-8b94-2f729fb372a6"
      },
      "outputs": [],
      "source": [
        "def inference(n_clients: int, protocol=None) -> torch.Tensor:\n",
        "    \"\"\"Perform encrypted inference on the test dataset over the network.\n",
        "    \"\"\"\n",
        "    # Get VM clients\n",
        "    parties = get_clients(n_clients)\n",
        "\n",
        "    # Setup the session for the computation\n",
        "    if protocol:\n",
        "        session = Session(parties=parties, protocol=protocol)\n",
        "    else:\n",
        "        session = Session(parties=parties)\n",
        "\n",
        "    SessionManager.setup_mpc(session)\n",
        "\n",
        "    # Split data and send data to clients\n",
        "    pointers = split_send(test_x, session)\n",
        "\n",
        "    # Encrypt model\n",
        "    mpc_model = model.share(session)\n",
        "\n",
        "    # Perform inference and measure time taken\n",
        "    start_time = time.time()\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for ptr in pointers:\n",
        "        encrypted_results = mpc_model(ptr)\n",
        "        plaintext_results = encrypted_results.reconstruct()\n",
        "        results.append(plaintext_results)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    print(f\"Time for inference: {end_time-start_time}s\")\n",
        "\n",
        "    predictions = torch.cat(results).reshape([-1])\n",
        "\n",
        "    #Calculate Loss\n",
        "    print(\"MSE Loss: \", loss_function(predictions,test_y).item())\n",
        "    return predictions"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d250bd5d",
      "metadata": {},
      "source": [
        "Now we can run our inference on an example network."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "56da0550",
      "metadata": {},
      "source": [
        "### Encrypted Inference (assuming \"semi-honest\" nodes)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "78d7d840",
      "metadata": {},
      "source": [
        "For the sake of example, lets' assume we have a network of 3 workers.\n",
        "\n",
        "Let's also assume that our `Falcon` protocol is assuming \"semi-honest\" nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "c30a2dea-29f6-492b-b6b5-0a66245e822b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c30a2dea-29f6-492b-b6b5-0a66245e822b",
        "outputId": "a0e8501f-ccc8-4df3-c397-30799d27d304"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Falcon on N=3 semi-honest workers:\n",
            "Time for inference: 0.1194368886979717s\n",
            "MSE Loss:  21.778549300512648\n"
          ]
        }
      ],
      "source": [
        "print(\"Falcon on N=3 semi-honest workers:\")\n",
        "predictions = inference(\n",
        "    n_clients=3,\n",
        "    Falcon(\"semi-honest\")\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "4cwpgzHMiad3",
      "metadata": {
        "id": "4cwpgzHMiad3"
      },
      "source": [
        "We can then compare the results of our encrypted inference to our plaintext inference.\n",
        "\n",
        "What do we find? The prediction values and mean squared error values are almost identical between the encrypted and plaintext versions.\n",
        "There are some very minor differences in the outputs due to precision loss.\n",
        "But, aside from that they perform indistinguishably well on the task at hand (or indistinguishably poorly, depending on how you look at it)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "48a11c19-1783-4947-b60d-cdd1377f086a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48a11c19-1783-4947-b60d-cdd1377f086a",
        "outputId": "9eae6239-bc53-475d-b0ce-3b6ee2443d0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index 0\n",
            "Expected Prediction: 5.0\n",
            "Plaintext Prediction Output 2.862741785703401\n",
            "Encrypted Prediction Output 2.8629437149153\n",
            "\n",
            "\n",
            "Index 1\n",
            "Expected Prediction: 11.899999618530273\n",
            "Plaintext Prediction Output 4.893105021494213\n",
            "Encrypted Prediction Output 4.893270911008\n",
            "\n",
            "\n",
            "Index 2\n",
            "Expected Prediction: 27.899999618530273\n",
            "Plaintext Prediction Output 20.178911721169953\n",
            "Encrypted Prediction Output 20.178953017991623\n",
            "\n",
            "\n",
            "Index 3\n",
            "Expected Prediction: 17.200000762939453\n",
            "Plaintext Prediction Output 11.998541888269916\n",
            "Encrypted Prediction Output 11.998668187754756\n",
            "\n",
            "\n",
            "Index 4\n",
            "Expected Prediction: 27.5\n",
            "Plaintext Prediction Output 19.139752971707028\n",
            "Encrypted Prediction Output 19.139784578666693\n",
            "\n",
            "Index 5\n",
            "Expected Prediction: 15.0\n",
            "Plaintext Prediction Output 10.023104710183637\n",
            "Encrypted Prediction Output 10.02325823903034\n",
            "\n",
            "\n",
            "Index 6\n",
            "Expected Prediction: 17.200000762939453\n",
            "Plaintext Prediction Output 15.837065783018554\n",
            "Encrypted Prediction Output 15.837146619743531\n",
            "\n",
            "\n",
            "Index 7\n",
            "Expected Prediction: 17.899999618530273\n",
            "Plaintext Prediction Output 2.0476697032780148\n",
            "Encrypted Prediction Output 2.04757452406785\n",
            "\n",
            "\n",
            "Index 8\n",
            "Expected Prediction: 16.299999237060547\n",
            "Plaintext Prediction Output 5.933970630070962\n",
            "Encrypted Prediction Output 5.934049355119542\n",
            "\n",
            "\n",
            "Index 9\n",
            "Expected Prediction: 7.0\n",
            "Plaintext Prediction Output 9.7053789371085908\n",
            "Encrypted Prediction Output 9.7052567740505351\n"
          ]
        }
      ],
      "source": [
        "for index in range(0,10):\n",
        "    print(f\"Index {index}\")\n",
        "    print(f\"Expected Prediction: {test_y[index]}\")\n",
        "    print(f\"Plaintext Prediction Output {plaintext_predictions[index].item()}\")\n",
        "    print(f\"Encrypted Prediction Output {predictions[index].item()}\")\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ZKEG6fr_ik5O",
      "metadata": {
        "id": "ZKEG6fr_ik5O"
      },
      "source": [
        "### Encrypted Inference (assuming \"malicious\" nodes)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "29f8ed27",
      "metadata": {},
      "source": [
        "The Falcon protocol can also be secured against \"malicious\" nodes hiding in an otherwise honest majority network.\n",
        "\n",
        "What does this mean in practice?\n",
        "It means that setting the security level to `malicious` will ensure that worker nodes avoid deviating from the protocol or tampering with the shares of data they're given."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "b390acfe-6a90-4a5f-922e-a9fe5fa35e12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b390acfe-6a90-4a5f-922e-a9fe5fa35e12",
        "outputId": "c976414f-1241-4c22-d11d-8988b3f55e66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Falcon on N=3 malicious workers:\n",
            "Time for inference: 0.647966524686441s\n",
            "MSE Loss:  21.778416803181585\n"
          ]
        }
      ],
      "source": [
        "print(\"Falcon on N=3 malicious workers:\")\n",
        "predictions = inference(\n",
        "    n_clients=3,\n",
        "    Falcon(\"malicious\")\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "779c987e",
      "metadata": {},
      "source": [
        "### SPDZ, and expanding the number of worker nodes"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "yvEkUcKpivB4",
      "metadata": {
        "id": "yvEkUcKpivB4"
      },
      "source": [
        "As mentioned when we set up our `inference()` function, SyMPC by default uses SPDZ and FSS protocol with \"semi-honest\" security type.\n",
        "\n",
        "The SPDZ protocol can be used for multiplication and related operations (convolution,matmul,etc).\n",
        "\n",
        "Functional Secret Sharing (FSS) for other operations such as comparison, equality, maxpool, etc.\n",
        "\n",
        "The SMPC protocol goes beyond the types of operations.\n",
        "\n",
        "FSS really only securely works for 2 parties.\n",
        "\n",
        "On the other hand, SPDZ can be extended to `N` arbitrary parties.\n",
        "\n",
        "Since linear regression uses only matmul, we can utilize the SPDZ protocol, which thus allows us to run linear regression with several parties in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "5367cb3b-8cec-42df-8e8d-a2896455c244",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5367cb3b-8cec-42df-8e8d-a2896455c244",
        "outputId": "6c305a86-bad8-4458-f5a3-867d0945ecd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SPDZ on N=3 semi-honest workers:\n",
            "Time for inference: 0.4948297386359114s\n",
            "MSE Loss:  21.778019022766458\n",
            "\n",
            "SPDZ on N=5 semi-honest workers:\n",
            "Time for inference: 1.31117314340541s\n",
            "MSE Loss:  21.778948081205161\n"
          ]
        }
      ],
      "source": [
        "print(\"SPDZ on N=3 semi-honest workers:\")\n",
        "predictions=inference(\n",
        "    n_clients=3\n",
        ")\n",
        "print(\"\\n\")\n",
        "print(\"SPDZ on N=5 semi-honest workers:\")\n",
        "predictions=inference(\n",
        "    n_clients=5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hVus0nG8i6GN",
      "metadata": {
        "id": "hVus0nG8i6GN"
      },
      "source": [
        "### Comparison"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "RUw1Ge-Vi83m",
      "metadata": {
        "id": "RUw1Ge-Vi83m"
      },
      "source": [
        "| **Protocol** | **Security Type** | **Parties** | **Inference Time (s)** |\n",
        "|--------------|-------------------|-------------|------------------------|\n",
        "| Plaintext    | N/A               | 1           | 0.00076441550071       |\n",
        "| Falcon       | Semi-honest       | 3           | 0.11943688869797       |\n",
        "| Falcon       | Malicious         | 3           | 0.64796652468644       |\n",
        "| SPDZ         | Semi-honest       | 3           | 0.49482973863591       |\n",
        "| SPDZ         | Semi-honest       | 5           | 1.31117314340541       |"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "yku2NyQ5i-ls",
      "metadata": {
        "id": "yku2NyQ5i-ls"
      },
      "source": [
        "This is only a very loose comparison, and your results may vary depending on your CPU hardware, or even if you're actually running the protocols in question on a network.\n",
        "\n",
        "The Falcoln protocol is the fastest in a 3-node setting, while SPDZ allows for inference with greater than 3 parties.\n",
        "Both of these protocols allow for inference with almost the same accuracy as plaintext."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "34997e25",
      "metadata": {},
      "source": [
        "## üìö References, Resources, and Further Reading"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "3a8bfddf",
      "metadata": {},
      "source": [
        "This is obviously a very simplified approach to running secure multi-party computation.\n",
        "Still, this is a good primer on the important foundational concepts.\n",
        "\n",
        "For further resources on implementing SCMP, we recommend the following resources (some of which inspired the work in this tutorial):\n",
        "\n",
        "- [OF PRIVACY AND PURSE STRINGS Subscribe Posted on January 8th, 2022 under Differential Privacy](https://blog.openmined.org/of-privacy-and-purse-strings/)\n",
        "- [SyMPC/examples/Encrypted-Inference-LinearRegression.ipynb](https://github.com/OpenMined/SyMPC/blob/main/examples/Encrypted-Inference-LinearRegression.ipynb)\n",
        "\n",
        "**OpenMined Syft Docs**\n",
        "- [Installation guides](https://openmined.github.io/PySyft/getting_started/index.html):\n",
        "    - [Linux](https://openmined.github.io/PySyft/install_tutorials/linux.html##)\n",
        "    - [OSX](https://openmined.github.io/PySyft/install_tutorials/osx_11_5_1.html#)\n",
        "    - [Windows](https://openmined.github.io/PySyft/install_tutorials/windows.html)\n",
        "- [User guide index](https://openmined.github.io/PySyft/user_guide/index.html)\n",
        "- [API Reference Index](https://openmined.github.io/PySyft/api_reference/index.html)\n",
        "- [Glossary](https://openmined.github.io/PySyft/deployment/glossary.html#privacy-budget)\n",
        "\n",
        "**OpenMined GitHub Repos**\n",
        "- [OpenMined/PySyft](https://github.com/OpenMined/PySyft) - The main one we use in this tutorial\n",
        "- [OpenMined/SyMPC](https://github.com/OpenMined/SyMPC) - A SMPC companion library for Syft\n",
        "- [OpenMined/SyferText](https://github.com/OpenMined/SyferText) - A privacy preserving NLP framework\n",
        "- [OpenMined/PyDP](https://github.com/OpenMined/PyDP) - The Python Differential Privacy Library. Built on top of: https://github.com/google/differential-privacy\n",
        "- [OpenMined/PipelineDP](https://github.com/OpenMined/PipelineDP) - PipelineDP is a Python framework for applying differentially private aggregations to large datasets using batch processing systems such as Apache Spark, Apache Beam, and more.\n",
        "- [OpenMined/TenSEAL](https://github.com/OpenMined/TenSEAL) - A library for doing homomorphic encryption operations on tensors\n",
        "- [OpenMined/datasets](https://github.com/OpenMined/datasets) - Example datasets used in OpenMined Demos."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
